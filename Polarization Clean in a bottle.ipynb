{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Polarization CLEAN in a bottle\n",
    "______________________________________________________________________________\n",
    "\n",
    "Algorithm: Pratley, Luke and Johnston-Hollit Melanie, An improved method for \n",
    "polarimetric image restoration in interferometry, 2016\n",
    "\n",
    "Implementation (C) B Hugo, SKA-SA\n",
    "\n",
    "Credit: L Bester's Hogbom CLEAN implementation, SKA-SA\n",
    "______________________________________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math as mp\n",
    "from numpy import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pyrap.tables import table as tbl\n",
    "import scipy.signal\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "from IPython.html.widgets import FloatProgress\n",
    "from IPython.display import display\n",
    "from mpl_toolkits.axes_grid1 import AxesGrid\n",
    "from scipy import optimize as opt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#(C) Landman Bester\n",
    "def twoD_Gaussian((x, y), amplitude, xo, yo, sigma_x, sigma_y, theta, offset):\n",
    "    xo = float(xo)\n",
    "    yo = float(yo)\n",
    "    a = (cos(theta)**2)/(2*sigma_x**2) + (sin(theta)**2)/(2*sigma_y**2)\n",
    "    b = -(sin(2*theta))/(4*sigma_x**2) + (sin(2*theta))/(4*sigma_y**2)\n",
    "    c = (sin(theta)**2)/(2*sigma_x**2) + (cos(theta)**2)/(2*sigma_y**2)\n",
    "    g = offset + amplitude*exp( - (a*((x-xo)**2) + 2*b*(x-xo)*(y-yo) + c*((y-yo)**2)))\n",
    "    return g.flatten()\n",
    "\n",
    "#(C) Landman Bester\n",
    "def fit_2D_Gaussian(PSF):\n",
    "    \"\"\"\n",
    "    Fit an elliptical Gaussian to the primary lobe of the PSF\n",
    "    \"\"\"\n",
    "    #Get the full width at half maximum height of the PSF\n",
    "    I = argwhere(PSF>=0.5*PSF.max())\n",
    "    #Create an array with these values at the same indices and zeros otherwise\n",
    "    lk,mk = PSF.shape\n",
    "    psf_fit = zeros([lk,mk])\n",
    "    psf_fit[I[:,0],I[:,1]] = PSF[I[:,0],I[:,1]]\n",
    "    # Create x and y indices\n",
    "    x = linspace(0, PSF.shape[0]-1, PSF.shape[0])\n",
    "    y = linspace(0, PSF.shape[1]-1, PSF.shape[1])\n",
    "    x, y = meshgrid(x, y)\n",
    "    # Set starting point of optimiser\n",
    "    initial_guess = (0.5,lk/2,mk/2,1.75,1.4,-4.0,0)\n",
    "    #Flatten the data\n",
    "    data = psf_fit.ravel()\n",
    "    #Fit the function (Gaussian for now)\n",
    "    popt, pcov = opt.curve_fit(twoD_Gaussian, (x, y), data, p0=initial_guess)\n",
    "    #Get function with fitted params\n",
    "    data_fitted = twoD_Gaussian((x, y), *popt)\n",
    "    #Normalise the psf to have a max value of one\n",
    "    data_fitted = data_fitted/data_fitted.max()\n",
    "    return data_fitted.reshape(lk,mk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_peak(Iresidue,Qresidue,Uresidue,Vresidue,mode=\"I\"):\n",
    "    \"\"\"\n",
    "    Finds peak in image or combination of images depending on mode\n",
    "    Q+iU: Luke Pratley's joint linear (P) polarization clean\n",
    "    I: Intensity only\n",
    "    \"\"\"\n",
    "    if mode == \"Q+iU\":\n",
    "        values_map = Qresidue + Uresidue*1.0j\n",
    "        peakmap = (np.abs(values_map))**2\n",
    "        p,q = (argwhere(peakmap==peakmap.max())[0]).squeeze()\n",
    "        pmin,qmin = (argwhere(peakmap==peakmap.min())[0]).squeeze()\n",
    "        Istar = values_map[p,q] #in Q and U the values may be negative or positive\n",
    "    elif mode == \"Q\":\n",
    "        peakmap = abs(Qresidue)\n",
    "        p,q = (argwhere(peakmap==peakmap.max())[0]).squeeze()\n",
    "        pmin,qmin = (argwhere(peakmap==peakmap.min())[0]).squeeze()\n",
    "        Istar = Qresidue[p,q]\n",
    "    elif mode == \"U\":\n",
    "        peakmap = abs(Uresidue)\n",
    "        p,q = (argwhere(peakmap==peakmap.max())[0]).squeeze()\n",
    "        pmin,qmin = (argwhere(peakmap==peakmap.min())[0]).squeeze()\n",
    "        Istar = Uresidue[p,q]\n",
    "    elif mode == \"V\":\n",
    "        peakmap = abs(Vresidue)\n",
    "        p,q = (argwhere(peakmap==peakmap.max())[0]).squeeze()\n",
    "        pmin,qmin = (argwhere(peakmap==peakmap.min())[0]).squeeze()\n",
    "        Istar = Vresidue[p,q]\n",
    "    elif mode == \"I\":\n",
    "        peakmap = Iresidue\n",
    "        p,q = (argwhere(peakmap==peakmap.max())[0]).squeeze()\n",
    "        pmin,qmin = (argwhere(peakmap==peakmap.min())[0]).squeeze()\n",
    "        Istar = Iresidue[p,q]\n",
    "    else:\n",
    "        raise ValueError(\"Peakfinding only works for mode one of [Q+iU, I]\")\n",
    "    return p,q,pmin,qmin,Istar\n",
    "\n",
    "def build_cleanmap(ICLEAN,QCLEAN,UCLEAN,VCLEAN,Istar,gamma,p,q,mode=\"I\"):\n",
    "    if mode == \"Q+iU\":\n",
    "        QCLEAN[p,q] += Istar.real*gamma\n",
    "        UCLEAN[p,q] += Istar.imag*gamma\n",
    "    elif mode == \"Q\":\n",
    "        QCLEAN[p,q] += Istar*gamma\n",
    "    elif mode == \"U\":\n",
    "        UCLEAN[p,q] += Istar*gamma\n",
    "    elif mode == \"V\":\n",
    "        VCLEAN[p,q] += Istar*gamma\n",
    "    elif mode == \"I\":\n",
    "        ICLEAN[p,q] += Istar*gamma\n",
    "    else:\n",
    "        raise ValueError(\"Cleanmap building only works for mode one of [Q+iU, I]\")\n",
    "        \n",
    "def update_residual(Iresidue,Qresidue,Uresidue,Vresidue,Istar,gamma,p,q,PSF,mode=\"I\"):\n",
    "    if mode == \"Q+iU\":\n",
    "        npix = Iresidue.shape[0] #Assuming square image\n",
    "        Qresidue -= gamma*Istar.real*PSF[npix - p:2*npix - p,\n",
    "                                         npix - q:2*npix - q] \n",
    "        Uresidue -= gamma*Istar.imag*PSF[npix - p:2*npix - p,\n",
    "                                         npix - q:2*npix - q]\n",
    "    elif mode == \"Q\":\n",
    "        npix = Iresidue.shape[0] #Assuming square image\n",
    "        Qresidue -= gamma*Istar*PSF[npix - p:2*npix - p,\n",
    "                                    npix - q:2*npix - q] \n",
    "    elif mode == \"U\":\n",
    "        npix = Iresidue.shape[0] #Assuming square image\n",
    "        Uresidue -= gamma*Istar*PSF[npix - p:2*npix - p,\n",
    "                                    npix - q:2*npix - q] \n",
    "    elif mode == \"V\":\n",
    "        npix = Iresidue.shape[0] #Assuming square image\n",
    "        Vresidue -= gamma*Istar*PSF[npix - p:2*npix - p,\n",
    "                                    npix - q:2*npix - q] \n",
    "    elif mode == \"I\":\n",
    "        npix = Iresidue.shape[0] #Assuming square image\n",
    "        Iresidue -= gamma*Istar*PSF[npix - p:2*npix - p,\n",
    "                                    npix - q:2*npix - q] \n",
    "    else:\n",
    "        raise ValueError(\"Residual subtraction only works for mode one of [Q+iU, I]\")\n",
    "        \n",
    "def convolve_model(CLEAN_BEAM,ICLEAN,QCLEAN,UCLEAN,VCLEAN,mode):\n",
    "    ICONV_MODEL = np.zeros(ICLEAN.shape)\n",
    "    QCONV_MODEL = np.zeros(ICLEAN.shape)\n",
    "    UCONV_MODEL = np.zeros(ICLEAN.shape)\n",
    "    VCONV_MODEL = np.zeros(ICLEAN.shape)\n",
    "    if mode == \"Q+iU\":\n",
    "        QCONV_MODEL[:,:] = scipy.signal.fftconvolve(QCLEAN,CLEAN_BEAM,mode='same') #, cval=0.0) #Fast using fft\n",
    "        UCONV_MODEL[:,:] = scipy.signal.fftconvolve(UCLEAN,CLEAN_BEAM,mode='same') #, cval=0.0) #Fast using fft\n",
    "    elif mode == \"Q\":\n",
    "        QCONV_MODEL[:,:] = scipy.signal.fftconvolve(QCLEAN,CLEAN_BEAM,mode='same') #, cval=0.0) #Fast using fft\n",
    "    elif mode == \"U\":\n",
    "        UCONV_MODEL[:,:] = scipy.signal.fftconvolve(UCLEAN,CLEAN_BEAM,mode='same') #, cval=0.0) #Fast using fft\n",
    "    elif mode == \"V\":\n",
    "        VCONV_MODEL[:,:] = scipy.signal.fftconvolve(VCLEAN,CLEAN_BEAM,mode='same') #, cval=0.0) #Fast using fft\n",
    "    elif mode == \"I\":\n",
    "        ICONV_MODEL[:,:] = scipy.signal.fftconvolve(ICLEAN,CLEAN_BEAM,mode='same') #, cval=0.0) #Fast using fft\n",
    "    else:\n",
    "        raise ValueError(\"Convolve model only works for mode one of [Q+iU, I]\")\n",
    "    return ICONV_MODEL, QCONV_MODEL, UCONV_MODEL, VCONV_MODEL\n",
    "\n",
    "def CLEAN_HOG(IDIRTY,QDIRTY,UDIRTY,VDIRTY,\n",
    "              PSF,gamma = 0.1,threshold = \"Default\", niter = \"Default\", \n",
    "              plot_on=True, mode=\"I\"):\n",
    "    \"\"\"\n",
    "    This is Hogbom CLEAN assuming a full cleaning window\n",
    "    Input: IDirty = the dirty image to be cleaned\n",
    "    PSF = the point spread function\n",
    "    gamma = the gain factor (must be less than one)\n",
    "    theshold = the threshold to clean up to\n",
    "    niter = the maximum number of iterations allowed\n",
    "    Output: ICLEAN = Clean model, IRESIDUAL = Residuals, \n",
    "            IRESTORE = Restored map, ICONV_CLEAN = Clean model convolved with clean beam\n",
    "    \n",
    "    \"\"\"\n",
    "    #deep copy dirties to first residues, want to keep the original dirty maps\n",
    "    ID = np.copy(IDIRTY)\n",
    "    QD = np.copy(QDIRTY) \n",
    "    UD = np.copy(UDIRTY) \n",
    "    VD = np.copy(VDIRTY) \n",
    "    #Check that all the dirty maps have the same shape\n",
    "    if (ID.shape[0] != QD.shape[0] or QD.shape[0] != UD.shape[0] or UD.shape[0] != VD.shape[0] or\n",
    "        ID.shape[1] != QD.shape[1] or QD.shape[1] != UD.shape[1] or UD.shape[1] != VD.shape[1]):\n",
    "            raise ValueError(\"Polarized dirties must have the same shape\")\n",
    "    #Check that PSF is twice the size of ID\n",
    "    if PSF.shape[0] != 2*ID.shape[0] or PSF.shape[1] != 2*ID.shape[1]:\n",
    "        raise ValueError(\"Warning PSF not right size\")\n",
    "    #Initialise array to store cleaned image\n",
    "    ICLEAN = zeros([npix,npix])\n",
    "    QCLEAN = zeros([npix,npix])\n",
    "    UCLEAN = zeros([npix,npix])\n",
    "    VCLEAN = zeros([npix,npix])\n",
    "\n",
    "    if niter == \"Default\":\n",
    "        niter = 3*npix\n",
    "\n",
    "    p,q,pmin,qmin,Istar = find_peak(ID,QD,UD,VD,mode)\n",
    "    if threshold==\"Default\":\n",
    "        threshold = 0.2*np.abs(Istar) #Imin + 0.001*(Istar - Imin)\n",
    "        print \"Threshold set at \", threshold\n",
    "    else:\n",
    "        print \"Assuming user set threshold\"\n",
    "\n",
    "    #CLEAN the image\n",
    "    i = 0 #counter index\n",
    "    pbar_clean = FloatProgress(min=0, max=100)\n",
    "    display(pbar_clean)\n",
    "\n",
    "    while np.abs(Istar) > threshold and i <= niter:\n",
    "        #First we set the\n",
    "        build_cleanmap(ICLEAN,QCLEAN,UCLEAN,VCLEAN,Istar,gamma,p,q,mode)\n",
    "        #Subtract out pixel\n",
    "        update_residual(ID,QD,UD,VD,Istar,gamma,p,q,PSF,mode)\n",
    "        #Get new indices where ID is max\n",
    "        p,q,_,_,Istar = find_peak(ID,QD,UD,VD,mode)\n",
    "        #Increment counter\n",
    "        i += 1\n",
    "        #Warn if niter exceeded\n",
    "        if i > niter:\n",
    "            print \"Warning: number of iterations exceeded\"\n",
    "            print \"Minimum ID = \", ID.max()\n",
    "        pbar_clean.value = i / float(niter) * 100.0\n",
    "    pbar_clean.value = 100 # done\n",
    "    print \"Done cleaning for mode %s after %d iterations. Now restoring...\" % (mode,i)\n",
    "    #get the ideal beam (fit 2D Gaussian to HWFH of PSF)\n",
    "    CLEAN_BEAM = fit_2D_Gaussian(PSF)\n",
    "    \n",
    "    #Now convolve ICLEAN with ideal beam\n",
    "    ICONV_MODEL, QCONV_MODEL, UCONV_MODEL, VCONV_MODEL = convolve_model(CLEAN_BEAM, ICLEAN, QCLEAN, UCLEAN, VCLEAN, mode)\n",
    "    \n",
    "    #Finally we add the residuals back to the image\n",
    "    IRESIDUE = ID\n",
    "    QRESIDUE = QD\n",
    "    URESIDUE = UD\n",
    "    VRESIDUE = VD\n",
    "    \n",
    "    IRESTORE = ICLEAN #ICONV_MODEL + IRESIDUE\n",
    "    QRESTORE = QCONV_MODEL + QRESIDUE\n",
    "    URESTORE = UCONV_MODEL + URESIDUE\n",
    "    VRESTORE = VCONV_MODEL + VRESIDUE\n",
    "    \n",
    "    return (ICLEAN, IRESIDUE, IRESTORE, ICONV_MODEL,QCLEAN, QRESIDUE, QRESTORE, QCONV_MODEL,\n",
    "            UCLEAN, URESIDUE, URESTORE, UCONV_MODEL,VCLEAN, VRESIDUE, VRESTORE, VCONV_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AA_filter:\n",
    "    \"\"\"\n",
    "    Anti-Aliasing filter\n",
    "    \n",
    "    Keyword arguments for __init__:\n",
    "    filter_half_support --- Half support (N) of the filter; the filter has a full support of N*2 + 1 taps\n",
    "    filter_oversampling_factor --- Number of spaces in-between grid-steps (improves gridding/degridding accuracy)\n",
    "    filter_type --- box (nearest-neighbour), sinc or gaussian_sinc\n",
    "    \"\"\"\n",
    "    half_sup = 0\n",
    "    oversample = 0\n",
    "    full_sup_wo_padding = 0\n",
    "    full_sup = 0\n",
    "    no_taps = 0\n",
    "    filter_taps = None\n",
    "    def __init__(self, filter_half_support, filter_oversampling_factor, filter_type):\n",
    "        self.half_sup = filter_half_support\n",
    "        self.oversample = filter_oversampling_factor\n",
    "        self.full_sup_wo_padding = (filter_half_support * 2 + 1)\n",
    "        self.full_sup = self.full_sup_wo_padding + 2 #+ padding\n",
    "        self.no_taps = self.full_sup + (self.full_sup - 1) * (filter_oversampling_factor - 1)\n",
    "        taps = np.arange(self.no_taps)/float(filter_oversampling_factor) - self.full_sup / 2\n",
    "        if filter_type == \"box\":\n",
    "            self.filter_taps = np.where((taps >= -0.5) & (taps <= 0.5),\n",
    "                                        np.ones([len(taps)]),np.zeros([len(taps)]))\n",
    "        elif filter_type == \"sinc\":\n",
    "            self.filter_taps = np.sinc(taps)\n",
    "        elif filter_type == \"gaussian_sinc\":\n",
    "            alpha_1=1.55\n",
    "            alpha_2=2.52\n",
    "            self.filter_taps = np.sin(np.pi/alpha_1*(taps+0.00000000001))/(np.pi*(taps+0.00000000001))*np.exp(-(taps/alpha_2)**2)\n",
    "        else:\n",
    "            raise ValueError(\"Expected one of 'box','sinc' or 'gausian_sinc'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class grid_it(object):\n",
    "    \n",
    "    def __init__(self,uvw,ref_lda,Nx,Ny,convolution_filter):\n",
    "        self.uvw = uvw\n",
    "        self.ref_lda = ref_lda\n",
    "        self.Nx = Nx\n",
    "        self.Ny = Ny\n",
    "        self.convolution_filter = convolution_filter\n",
    "        \n",
    "    def give_IR(self,vis):\n",
    "        filter_index = np.arange(-self.convolution_filter.half_sup,self.convolution_filter.half_sup+1)\n",
    "        measurement_regular = np.zeros([vis.shape[1],self.Ny,self.Nx],dtype=np.complex) #one grid for the resampled visibilities\n",
    "\n",
    "        for r in range(0,uvw.shape[0]):\n",
    "            for c in range(vis.shape[1]):\n",
    "                scaled_uv = self.uvw[r,:] / self.ref_lda[c] \n",
    "                disc_u = int(scaled_uv[0])\n",
    "                disc_v = int(scaled_uv[1])\n",
    "                frac_u_offset = int((self.convolution_filter.half_sup + 1 + (-scaled_uv[0] + disc_u)) * self.convolution_filter.oversample)\n",
    "                frac_v_offset = int((self.convolution_filter.half_sup + 1 + (-scaled_uv[1] + disc_v)) * self.convolution_filter.oversample)\n",
    "                if (disc_v + self.Ny // 2 + self.convolution_filter.half_sup >= self.Ny or \n",
    "                    disc_u + self.Nx // 2 + self.convolution_filter.half_sup >= self.Nx or\n",
    "                    disc_v + self.Ny // 2 - self.convolution_filter.half_sup < 0 or \n",
    "                    disc_u + self.Nx // 2 - self.convolution_filter.half_sup < 0): \n",
    "                    continue\n",
    "                for conv_v in filter_index:\n",
    "                    v_tap = self.convolution_filter.filter_taps[conv_v * self.convolution_filter.oversample + frac_v_offset]  \n",
    "                    grid_pos_v = disc_v + conv_v + self.Ny // 2\n",
    "                    for conv_u in filter_index:\n",
    "                        u_tap = self.convolution_filter.filter_taps[conv_u * self.convolution_filter.oversample + frac_u_offset]\n",
    "                        conv_weight = v_tap * u_tap\n",
    "                        grid_pos_u = disc_u + conv_u + self.Ny // 2\n",
    "                        measurement_regular[c,grid_pos_v,grid_pos_u] += vis[r,c] * conv_weight              \n",
    "        dirty = np.zeros(measurement_regular.shape,dtype=measurement_regular.dtype)\n",
    "        for c in range(vis.shape[1]):\n",
    "            dirty[c,:,:] = np.fft.fftshift(np.fft.ifft2(np.fft.ifftshift(measurement_regular[c,:,:])))\n",
    "        return dirty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def grid_ifft(vis,uvw,ref_lda,Nx,Ny,convolution_filter):\n",
    "    \"\"\"\n",
    "    Convolutional gridder (continnuum)\n",
    "    \n",
    "    Keyword arguments:\n",
    "    vis --- Visibilities as sampled by the interferometer\n",
    "    uvw --- interferometer's scaled uvw coordinates. (Prerequisite: these uv points are already scaled by the simularity\n",
    "            theorem, such that -N_x*Cell_l*0.5 <= theta_l <= N_x*Cell_l*0.5 and\n",
    "            -N_y*Cell_m*0.5 <= theta_m <= N_y*Cell_m*0.5\n",
    "    ref_lda --- array of reference lambdas (size of vis channels)\n",
    "    Nx,Ny --- size of image in pixels\n",
    "    convolution_filter --- pre-instantiated AA_filter anti-aliasing filter object\n",
    "    \"\"\"\n",
    "    assert vis.shape[1] == ref_lda.shape[0], (vis.shape[1], ref_lda.shape[0])\n",
    "    filter_index = np.arange(-convolution_filter.half_sup,convolution_filter.half_sup+1)\n",
    "    measurement_regular = np.zeros([vis.shape[1],vis.shape[2],Ny,Nx],dtype=np.complex) #one grid for the resampled visibilities\n",
    "    #for deconvolution the PSF should be 2x size of the image (see Hogbom CLEAN for details):\n",
    "    sampling_regular = np.zeros([vis.shape[1],2*Ny,2*Nx],dtype=np.complex) #one grid for the resampled sampling function\n",
    "    \n",
    "    pbar = FloatProgress(min=0, max=100)\n",
    "    display(pbar)\n",
    "    for r in range(0,uvw.shape[0]):\n",
    "        pbar.value = r / float(uvw.shape[0]) * 100\n",
    "        for c in range(vis.shape[1]):\n",
    "            scaled_uv = uvw[r,:] / ref_lda[c] \n",
    "            disc_u = int(scaled_uv[0])\n",
    "            disc_v = int(scaled_uv[1])\n",
    "            frac_u_offset = int((convolution_filter.half_sup + 1 + (-scaled_uv[0] + disc_u)) * convolution_filter.oversample)\n",
    "            frac_v_offset = int((convolution_filter.half_sup + 1 + (-scaled_uv[1] + disc_v)) * convolution_filter.oversample)\n",
    "            disc_u_psf = int(scaled_uv[0]*2)\n",
    "            disc_v_psf = int(scaled_uv[1]*2)\n",
    "            frac_u_offset_psf = int((convolution_filter.half_sup + 1 + (-scaled_uv[0]*2 + disc_u_psf)) * convolution_filter.oversample)\n",
    "            frac_v_offset_psf = int((convolution_filter.half_sup + 1 + (-scaled_uv[1]*2 + disc_v_psf)) * convolution_filter.oversample)\n",
    "            if (disc_v + Ny // 2 + convolution_filter.half_sup >= Ny or \n",
    "                disc_u + Nx // 2 + convolution_filter.half_sup >= Nx or\n",
    "                disc_v + Ny // 2 - convolution_filter.half_sup < 0 or \n",
    "                disc_u + Nx // 2 - convolution_filter.half_sup < 0): \n",
    "                continue\n",
    "            for conv_v in filter_index:\n",
    "                v_tap = convolution_filter.filter_taps[conv_v * convolution_filter.oversample + frac_v_offset]  \n",
    "                v_tap_psf = convolution_filter.filter_taps[conv_v * convolution_filter.oversample + frac_v_offset_psf]  \n",
    "                grid_pos_v = disc_v + conv_v + Ny // 2\n",
    "                grid_pos_v_psf = disc_v_psf + conv_v + Ny\n",
    "                for conv_u in filter_index:\n",
    "                    u_tap = convolution_filter.filter_taps[conv_u * convolution_filter.oversample + frac_u_offset]\n",
    "                    u_tap_psf = convolution_filter.filter_taps[conv_u * convolution_filter.oversample + frac_u_offset_psf]\n",
    "                    conv_weight = v_tap * u_tap\n",
    "                    conv_weight_psf = v_tap_psf * u_tap_psf\n",
    "                    grid_pos_u = disc_u + conv_u + Ny // 2\n",
    "                    grid_pos_u_psf = disc_u_psf + conv_u + Nx\n",
    "                    for p in range(vis.shape[2]):\n",
    "                        measurement_regular[c,p,grid_pos_v,grid_pos_u] += vis[r,c,p] * conv_weight\n",
    "                    sampling_regular[c,grid_pos_v_psf,grid_pos_u_psf] += (1+0.0j) * conv_weight_psf\n",
    "                    \n",
    "    dirty = np.zeros(measurement_regular.shape,dtype=measurement_regular.dtype)\n",
    "    psf = np.zeros(sampling_regular.shape,dtype=sampling_regular.dtype)\n",
    "    \n",
    "    for c in range(vis.shape[1]):\n",
    "        for p in range(vis.shape[2]):\n",
    "            dirty[c,p,:,:] = np.fft.fftshift(np.fft.ifft2(np.fft.ifftshift(measurement_regular[c,p,:,:])))\n",
    "        psf[c,:,:] = np.fft.fftshift(np.fft.ifft2(np.fft.ifftshift(sampling_regular[c,:,:])))\n",
    "    return dirty,psf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Collection of DFT routines for accuracy\n",
    "def get_lmn(l,m):\n",
    "    \"\"\"\n",
    "    Get (l,m,n) triple. uvw is a tuple containg u, v and w coordinates for the measurement\n",
    "    set and l and m are coordinates on the sky.\n",
    "    \"\"\"\n",
    "    #First get n for each pair of l and m\n",
    "    Nx = l.size #numbere of pixels in l\n",
    "    Ny = m.size #number of pixels in m\n",
    "    n = np.zeros(Nx*Ny) #array to store\n",
    "    lmn = np.zeros([Nx*Ny,3]) #array to store combos of l, m and n\n",
    "    for i in range(Nx):\n",
    "        for j in range(Ny):\n",
    "            n[i*Ny + j] = np.sqrt(1.0 - l[i]**2 - m[j]**2)\n",
    "            lmn[i*Ny + j,0] = l[i]\n",
    "            lmn[i*Ny + j,1] = m[j]\n",
    "            lmn[i*Ny + j,2] = n[i*Ny+j] - 1\n",
    "    return lmn\n",
    "\n",
    "def set_kernels(Nx,Ny,lmn,uvw,ref_lambda):\n",
    "    \"\"\"\n",
    "    Sets the DFT kernels for each channel\n",
    "    \"\"\"\n",
    "    Nch = ref_lambda.size\n",
    "    Nv = uvw.shape[0]\n",
    "    tmp = -2.0j*np.pi*dot(uvw,lmn.T)\n",
    "    K = np.zeros([Nch,Nv, Nx*Ny],dtype=complex)\n",
    "    #invK = np.zeros([Nch,Nx*Ny,Nv],dtype=complex)\n",
    "    for k in range(Nch):\n",
    "            K[k,:,:] = np.exp(tmp/ref_lambda[k])\n",
    "            #invK[k,:,:] = np.exp(-tmp.T/ref_lambda[k])\n",
    "    return K #invK\n",
    "\n",
    "def DFT(I,K,n):\n",
    "    tmp = np.zeros([K.shape[0],K.shape[1]],dtype=complex)\n",
    "    for i in range(K.shape[0]):\n",
    "        tmp[i,:] = np.dot(K[i,:,:],I[i,:]/n)\n",
    "    return tmp\n",
    "\n",
    "def iDFT(vis,invK,n):\n",
    "    tmp = np.zeros([invK.shape[0],invK.shape[1]],dtype=complex)\n",
    "    for i in range(invK.shape[0]):\n",
    "        tmp[i,:] = n*np.dot(invK[i,:,:],vis[:,i])    \n",
    "    return tmp\n",
    "\n",
    "def flatten_ID(I):\n",
    "    Nx = I.shape[1]\n",
    "    Ny = I.shape[2]\n",
    "    Iflat = np.zeros([1,Nx*Ny])\n",
    "    for i in range(Nx):\n",
    "        for j in range(Ny):\n",
    "            Iflat[0,i*Ny + j] = I[0,i,j]\n",
    "    return Iflat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulate sky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import subprocess\n",
    "#import Cattery.Siamese \n",
    "#turbo_sim_path = \"%s/turbo-sim.py\" % Cattery.Siamese.__path__[0]\n",
    "#subprocess.check_call(\"cd DATA ; makems pols.makems.parset ; meqtree-pipeliner.py -c polarized_sky.tdl --mt=4 @pol %s =simulate\" % turbo_sim_path, shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Dirty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Load in MS\n",
    "ms = tbl(\"DATA/polarized_sky.MS_p0/\")\n",
    "\n",
    "#Get freq info\n",
    "msfreq = tbl(\"DATA/polarized_sky.MS_p0::SPECTRAL_WINDOW\")\n",
    "\n",
    "#Get pointing center\n",
    "msfield = tbl(\"DATA/polarized_sky.MS_p0::FIELD\")\n",
    "ra0, dec0 = msfield.getcol(\"PHASE_DIR\").squeeze() #in radians\n",
    "\n",
    "#Set AA filter\n",
    "aa = AA_filter(3,63,\"sinc\")\n",
    "\n",
    "#Some constants and conversion factors\n",
    "c = 2.99792458e8 #speed of light\n",
    "npix = 128 #1025\n",
    "ARCSEC2RAD = 4.8481e-6\n",
    "delta_pix = 2 * ARCSEC2RAD * 2 * 2 * 2\n",
    "uv_scale = npix * delta_pix\n",
    "\n",
    "#Select subset of data\n",
    "nchan = 5 #-1 to select all (NOTE this selects all but the last)\n",
    "nrows = 1000 #-1 to select all\n",
    "uvw = ms.getcol(\"UVW\")[0:nrows,:] \n",
    "vis = ms.getcol(\"DATA\")[0:nrows,0:nchan,:]\n",
    "#Delete autocorelations\n",
    "I = np.argwhere(uvw[:,0] == 0.0).squeeze()\n",
    "uvw = np.delete(uvw,I,axis=0)\n",
    "scaled_uvw = uvw * uv_scale\n",
    "vis = np.delete(vis,I,axis=0)\n",
    "\n",
    "#Get frequencies\n",
    "ref_freq = msfreq.getcol(\"CHAN_FREQ\").squeeze()[0:nchan]\n",
    "\n",
    "#Close tables\n",
    "ms.close()\n",
    "msfreq.close()\n",
    "msfield.close()\n",
    "\n",
    "#Get wavelengths\n",
    "ref_lambda = c / ref_freq\n",
    "\n",
    "#Compute dirty using gridder\n",
    "print \"Gridding\"\n",
    "dirty,psf = grid_ifft(vis,scaled_uvw,ref_lambda,npix,npix,aa)\n",
    "\n",
    "#Get ID from gridder for comparison\n",
    "ID2 = np.real((dirty[:,0,:,:]+dirty[:,3,:,:])*0.5)/4.0\n",
    "\n",
    "psf2 = np.abs(psf)\n",
    "\n",
    "#Normalise ID and PSF\n",
    "#for i in range(nchan):\n",
    "#    ID2[i,:,:] /= (np.max(psf2[i,:,:])*4) #x4 because the N**2 FFT normalization factor on a square image doubles the size\n",
    "#    psf2[i,:,:] /= np.max(psf2[i,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Here we get ID and PSF using DFT\n",
    "#Set ra and dec\n",
    "ra = ra0 + np.linspace(ra0 - npix*delta_pix/2.0,ra0 + npix*delta_pix/2.0,npix)\n",
    "ra_PSF  = ra0 + np.linspace(ra0 - npix*delta_pix,ra0 + npix*delta_pix,2*npix)\n",
    "delta_ra = ra - ra0\n",
    "delta_ra_PSF = ra_PSF - ra0\n",
    "dec = dec0 + np.linspace(dec0 - npix*delta_pix/2.0,dec0 + npix*delta_pix/2.0,npix)\n",
    "dec_PSF = dec0 + np.linspace(dec0 - npix*delta_pix,dec0 + npix*delta_pix,2*npix)\n",
    "\n",
    "#Get corresponding l and m\n",
    "l = (np.cos(dec)*np.sin(delta_ra))\n",
    "l_PSF = (np.cos(dec_PSF)*np.sin(delta_ra_PSF))\n",
    "m = (-np.sin(dec)*np.cos(dec0) - np.cos(dec)*np.sin(dec0)*cos(delta_ra))\n",
    "m_PSF = (-np.sin(dec_PSF)*np.cos(dec0) - np.cos(dec_PSF)*np.sin(dec0)*cos(delta_ra_PSF))\n",
    "\n",
    "print \"Getting lmn\"\n",
    "lmn = get_lmn(l,m)\n",
    "n = lmn[:,2] + 1.0\n",
    "lmn_PSF = get_lmn(l_PSF,m_PSF)\n",
    "n_PSF = lmn_PSF[:,2] + 1.0\n",
    "\n",
    "print \"Getting DFT kernels for PSF\"\n",
    "invK_PSF = set_kernels(2*npix,2*npix,lmn_PSF,uvw,ref_lambda)\n",
    "\n",
    "print \"Computing PSF\"\n",
    "PSF = iDFT(np.ones([vis.shape[0],nchan]),invK_PSF,n_PSF) #np.abs(dot(invK[0,:,:],np.ones(vis.shape[0])))\n",
    "PSF = np.abs(PSF.reshape(nchan,2*npix,2*npix))\n",
    "\n",
    "del(invK_PSF)\n",
    "del(l_PSF)\n",
    "del(m_PSF)\n",
    "del(lmn_PSF)\n",
    "del(n_PSF)\n",
    "\n",
    "print \"Getting DFT kernels\"\n",
    "invK = set_kernels(npix,npix,lmn,uvw,ref_lambda)\n",
    "K = np.zeros([nchan,uvw.shape[0],npix*npix])\n",
    "for i in range(nchan):\n",
    "    K[i,:,:] = invK[i,:,:].conjugate().T\n",
    "\n",
    "print \"Doing iDFT\"\n",
    "visI = (vis[:,:,0] + vis[:,:,3])*0.5\n",
    "ID = np.real(iDFT(visI,invK,n))\n",
    "\n",
    "IDt = ID.copy()\n",
    "\n",
    "print \"Doing DFT\"\n",
    "visI_pred = DFT(ID,K,n)\n",
    "\n",
    "#Reshape into image\n",
    "ID = ID.reshape(nchan,npix,npix)\n",
    "\n",
    "#Normalise ID and PSF\n",
    "for i in range(nchan):\n",
    "    ID[i,:,:] /= (np.max(PSF[i,:,:])) #x4 because the N**2 FFT normalization factor on a square image doubles the size\n",
    "    PSF[i,:,:] /= np.max(PSF[i,:,:])\n",
    "\n",
    "#print np.allclose(visI,visI_pred,rtol=1e-03, atol=1e-03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ch = 0\n",
    "#Plot results for comparison\n",
    "Fig = plt.figure(1,(15,15))\n",
    "grid = ImageGrid(Fig, 111,  # similar to subplot(111)\n",
    "                nrows_ncols=(1, 2),\n",
    "                direction=\"row\",\n",
    "                axes_pad=0.5,\n",
    "                add_all=True,\n",
    "                label_mode=\"1\",\n",
    "                share_all=True,\n",
    "                cbar_location=\"right\",\n",
    "                cbar_mode=\"each\",\n",
    "                cbar_size=\"3%\")\n",
    "\n",
    "grid[0].set_title(\"ID_DFT\")\n",
    "im = grid[0].imshow(np.fliplr(ID[ch,:,:]).T, interpolation=\"nearest\", cmap=\"cubehelix\")\n",
    "grid[0].cax.colorbar(im)\n",
    "grid[1].set_title(\"ID_grid\")\n",
    "im = grid[1].imshow(ID2[ch,:,:], interpolation=\"nearest\", cmap=\"cubehelix\")\n",
    "grid[1].cax.colorbar(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Plot results for comparison\n",
    "Fig = plt.figure(1,(15,15))\n",
    "grid = ImageGrid(Fig, 111,  # similar to subplot(111)\n",
    "                nrows_ncols=(1, 2),\n",
    "                direction=\"row\",\n",
    "                axes_pad=0.5,\n",
    "                add_all=True,\n",
    "                label_mode=\"1\",\n",
    "                share_all=True,\n",
    "                cbar_location=\"right\",\n",
    "                cbar_mode=\"each\",\n",
    "                cbar_size=\"3%\")\n",
    "\n",
    "\n",
    "grid[0].set_title(\"PSF_DFT\")\n",
    "im = grid[0].imshow(np.fliplr(PSF[ch,:,:]).T, interpolation=\"nearest\", cmap=\"cubehelix\")\n",
    "grid[0].cax.colorbar(im)\n",
    "grid[1].set_title(\"PSF_grid\")\n",
    "im = grid[1].imshow(np.abs(psf2[ch,:,:]), interpolation=\"nearest\", cmap=\"cubehelix\")\n",
    "grid[1].cax.colorbar(im)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlations -> Stokes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "I = np.real((dirty[:,0,:,:]+dirty[:,3,:,:])*0.5)\n",
    "Q = np.real((dirty[:,0,:,:]-dirty[:,3,:,:])*0.5)\n",
    "U = np.real((dirty[:,1,:,:]+dirty[:,2,:,:])*0.5)\n",
    "V = np.imag((dirty[:,1,:,:]-dirty[:,2,:,:])*0.5)\n",
    "\n",
    "#assume psf is the same for all polarizations:\n",
    "I_PSF = np.abs(psf)\n",
    "Q_PSF = np.abs(psf)\n",
    "U_PSF = np.abs(psf)\n",
    "V_PSF = np.abs(psf)\n",
    "\n",
    "#Set normalisation for each channel\n",
    "for i in range(nchan):\n",
    "    I[i,:,:] /= (np.max(I_PSF[i,:,:])*4) #x4 because the N**2 FFT normalization factor on a square image doubles the size\n",
    "    Q[i,:,:] /= (np.max(Q_PSF[i,:,:])*4)\n",
    "    U[i,:,:] /= (np.max(U_PSF[i,:,:])*4)\n",
    "    V[i,:,:] /= (np.max(V_PSF[i,:,:])*4)\n",
    "    I_PSF[i,:,:] /= np.max(I_PSF[i,:,:])\n",
    "    Q_PSF[i,:,:] /= np.max(Q_PSF[i,:,:])\n",
    "    U_PSF[i,:,:] /= np.max(U_PSF[i,:,:])\n",
    "    V_PSF[i,:,:] /= np.max(V_PSF[i,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dirty map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ch = 0\n",
    "F = plt.figure(1,(15,15))\n",
    "grid = ImageGrid(F, 111,  # similar to subplot(111)\n",
    "                nrows_ncols=(2, 2),\n",
    "                direction=\"row\",\n",
    "                axes_pad=0.5,\n",
    "                add_all=True,\n",
    "                label_mode=\"1\",\n",
    "                share_all=True,\n",
    "                cbar_location=\"right\",\n",
    "                cbar_mode=\"each\",\n",
    "                cbar_size=\"3%\")\n",
    "\n",
    "grid[0].set_title(\"I\")\n",
    "im = grid[0].imshow(I[ch,:,:], interpolation=\"nearest\", cmap=\"cubehelix\")\n",
    "grid[0].cax.colorbar(im)\n",
    "grid[1].set_title(\"Q\")\n",
    "im = grid[1].imshow(Q[ch,:,:], interpolation=\"nearest\", cmap=\"cubehelix\")\n",
    "grid[1].cax.colorbar(im)\n",
    "grid[2].set_title(\"U\")\n",
    "im = grid[2].imshow(U[ch,:,:], interpolation=\"nearest\", cmap=\"cubehelix\")\n",
    "grid[2].cax.colorbar(im)\n",
    "grid[3].set_title(\"V\")\n",
    "im = grid[3].imshow(V[ch,:,:], interpolation=\"nearest\", cmap=\"cubehelix\")\n",
    "grid[3].cax.colorbar(im)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PSF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ch = 0\n",
    "F = plt.figure(1,(15,15))\n",
    "grid = ImageGrid(F, 111,  # similar to subplot(111)\n",
    "                nrows_ncols=(2, 2),\n",
    "                direction=\"row\",\n",
    "                axes_pad=0.5,\n",
    "                add_all=True,\n",
    "                label_mode=\"1\",\n",
    "                share_all=True,\n",
    "                cbar_location=\"right\",\n",
    "                cbar_mode=\"each\",\n",
    "                cbar_size=\"3%\")\n",
    "\n",
    "grid[0].set_title(\"I PSF\")\n",
    "im = grid[0].imshow(I_PSF[ch], interpolation=\"nearest\", cmap=\"cubehelix\")\n",
    "grid[0].cax.colorbar(im)\n",
    "grid[1].set_title(\"Q PSF\")\n",
    "im = grid[1].imshow(Q_PSF[ch], interpolation=\"nearest\", cmap=\"cubehelix\")\n",
    "grid[1].cax.colorbar(im)\n",
    "grid[2].set_title(\"U PSF\")\n",
    "im = grid[2].imshow(U_PSF[ch], interpolation=\"nearest\", cmap=\"cubehelix\")\n",
    "grid[2].cax.colorbar(im)\n",
    "grid[3].set_title(\"V PSF\")\n",
    "im = grid[3].imshow(V_PSF[ch], interpolation=\"nearest\", cmap=\"cubehelix\")\n",
    "grid[3].cax.colorbar(im)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean (per channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ch = 0\n",
    "print \"Cleaning I...\"\n",
    "I_clean,I_residue,I_restored,I_convmodel, _, _, _, _, _, _, _, _ , _, _, _, _ = CLEAN_HOG(I[ch],Q[ch],U[ch],V[ch],I_PSF[ch],mode=\"I\")\n",
    "print \"\\t ...done\"\n",
    "print \"Cleaning Q+Ui...\"\n",
    "_, _, _, _, Q_clean, Q_residue, Q_restored, Q_convmodel, U_clean, U_residue, U_restored, U_convmodel, _, _, _, _ = CLEAN_HOG(I[ch],Q[ch],U[ch],V[ch],I_PSF[ch],mode=\"Q+iU\")\n",
    "print \"\\t ...done\"\n",
    "print \"Cleaning V...\"\n",
    "_, _, _, _, _, _, _, _, _, _, _, _, V_clean, V_residue, V_restored, V_convmodel = CLEAN_HOG(I[ch],Q[ch],U[ch],V[ch],I_PSF[ch],mode=\"V\")\n",
    "print \"\\t ...done\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaned I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "F = plt.figure(1,(15,15))\n",
    "grid = ImageGrid(F, 111,  # similar to subplot(111)\n",
    "                nrows_ncols=(2, 2),\n",
    "                direction=\"row\",\n",
    "                axes_pad=0.5,\n",
    "                add_all=True,\n",
    "                label_mode=\"1\",\n",
    "                share_all=True,\n",
    "                cbar_location=\"right\",\n",
    "                cbar_mode=\"each\",\n",
    "                cbar_size=\"3%\")\n",
    "\n",
    "grid[0].set_title(\"I Restored\")\n",
    "im = grid[0].imshow(I_restored, interpolation=\"nearest\", cmap=\"cubehelix\")\n",
    "grid[0].cax.colorbar(im)\n",
    "grid[1].set_title(\"I Residue\")\n",
    "im = grid[1].imshow(I_residue, interpolation=\"nearest\", cmap=\"cubehelix\")\n",
    "grid[1].cax.colorbar(im)\n",
    "grid[2].set_title(\"I Dirty\")\n",
    "im = grid[2].imshow(I[ch], interpolation=\"nearest\", cmap=\"cubehelix\")\n",
    "grid[2].cax.colorbar(im)\n",
    "grid[3].set_title(\"I convolved clean map\")\n",
    "im = grid[3].imshow(I_convmodel, interpolation=\"nearest\", cmap=\"cubehelix\")\n",
    "grid[3].cax.colorbar(im)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Cleaned Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "F = plt.figure(1,(15,15))\n",
    "grid = ImageGrid(F, 111,  # similar to subplot(111)\n",
    "                nrows_ncols=(2, 2),\n",
    "                direction=\"row\",\n",
    "                axes_pad=0.5,\n",
    "                add_all=True,\n",
    "                label_mode=\"1\",\n",
    "                share_all=True,\n",
    "                cbar_location=\"right\",\n",
    "                cbar_mode=\"each\",\n",
    "                cbar_size=\"3%\")\n",
    "\n",
    "grid[0].set_title(\"Q Restored\")\n",
    "im = grid[0].imshow(Q_restored, interpolation=\"nearest\", cmap=\"cubehelix\")\n",
    "grid[0].cax.colorbar(im)\n",
    "grid[1].set_title(\"Q Residue\")\n",
    "im = grid[1].imshow(Q_residue, interpolation=\"nearest\", cmap=\"cubehelix\")\n",
    "grid[1].cax.colorbar(im)\n",
    "grid[2].set_title(\"Q Dirty\")\n",
    "im = grid[2].imshow(Q[ch], interpolation=\"nearest\", cmap=\"cubehelix\")\n",
    "grid[2].cax.colorbar(im)\n",
    "grid[3].set_title(\"Q convolved clean map\")\n",
    "im = grid[3].imshow(Q_convmodel, interpolation=\"nearest\", cmap=\"cubehelix\")\n",
    "grid[3].cax.colorbar(im)\n",
    "plt.show()\n",
    "\n",
    "F = plt.figure(1,(15,15))\n",
    "grid = ImageGrid(F, 111,  # similar to subplot(111)\n",
    "                nrows_ncols=(2, 2),\n",
    "                direction=\"row\",\n",
    "                axes_pad=0.5,\n",
    "                add_all=True,\n",
    "                label_mode=\"1\",\n",
    "                share_all=True,\n",
    "                cbar_location=\"right\",\n",
    "                cbar_mode=\"each\",\n",
    "                cbar_size=\"3%\")\n",
    "\n",
    "grid[0].set_title(\"U Restored\")\n",
    "im = grid[0].imshow(U_restored, interpolation=\"nearest\", cmap=\"cubehelix\")\n",
    "grid[0].cax.colorbar(im)\n",
    "grid[1].set_title(\"U Residue\")\n",
    "im = grid[1].imshow(U_residue, interpolation=\"nearest\", cmap=\"cubehelix\")\n",
    "grid[1].cax.colorbar(im)\n",
    "grid[2].set_title(\"U Dirty\")\n",
    "im = grid[2].imshow(U[ch], interpolation=\"nearest\", cmap=\"cubehelix\")\n",
    "grid[2].cax.colorbar(im)\n",
    "grid[3].set_title(\"U convolved clean map\")\n",
    "im = grid[3].imshow(U_convmodel, interpolation=\"nearest\", cmap=\"cubehelix\")\n",
    "grid[3].cax.colorbar(im)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Circular polarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "F = plt.figure(1,(15,15))\n",
    "grid = ImageGrid(F, 111,  # similar to subplot(111)\n",
    "                nrows_ncols=(2, 2),\n",
    "                direction=\"row\",\n",
    "                axes_pad=0.5,\n",
    "                add_all=True,\n",
    "                label_mode=\"1\",\n",
    "                share_all=True,\n",
    "                cbar_location=\"right\",\n",
    "                cbar_mode=\"each\",\n",
    "                cbar_size=\"3%\")\n",
    "\n",
    "grid[0].set_title(\"V Restored\")\n",
    "im = grid[0].imshow(V_restored, interpolation=\"nearest\", cmap=\"cubehelix\")\n",
    "grid[0].cax.colorbar(im)\n",
    "grid[1].set_title(\"V Residue\")\n",
    "im = grid[1].imshow(V_residue, interpolation=\"nearest\", cmap=\"cubehelix\")\n",
    "grid[1].cax.colorbar(im)\n",
    "grid[2].set_title(\"V Dirty\")\n",
    "im = grid[2].imshow(V[ch], interpolation=\"nearest\", cmap=\"cubehelix\")\n",
    "grid[2].cax.colorbar(im)\n",
    "grid[3].set_title(\"V convolved clean map\")\n",
    "im = grid[3].imshow(V_convmodel, interpolation=\"nearest\", cmap=\"cubehelix\")\n",
    "grid[3].cax.colorbar(im)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joint Polarization vs. Seperate Polarization CLEAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I compare the Pratley and Johnston-Hollitt joint polarization CLEAN algorithm with standard seperate polarization CLEAN. First I keep the frame centred as-is (shown above), then I rotate the frame to simulate a different choice of frame for the feeds, clean the images produced and then derotate the image. The result should be the same as for the original frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Let P = Q + iU, then rotate each complex number by theta:\n",
    "theta = np.deg2rad(65)\n",
    "P = Q[ch] + 1.0j*U[ch]\n",
    "RP = P * np.exp(1.0j * theta)\n",
    "#joint clean on rotated frame:\n",
    "_, _, _, _, RQ_clean, RQ_residue, RQ_restored, RQ_convmodel, RU_clean, RU_residue, RU_restored, RU_convmodel, _, _, _, _ = CLEAN_HOG(I[ch],RP.real,RP.imag,V[ch],I_PSF[ch],mode=\"Q+iU\")\n",
    "#unrotate the frame:\n",
    "RPClean = RQ_convmodel + 1.0j*RU_convmodel\n",
    "PClean = RPClean * np.exp(1.0j * (-theta))\n",
    "\n",
    "plt.figure(1,(5,5))\n",
    "plt.title(\"Luke's Joint polarization CLEAN\")\n",
    "p1 = plt.scatter(PClean.real,PClean.imag, marker=\"+\", color='blue', label='Rotated frame')\n",
    "p2 = plt.scatter(Q_convmodel,U_convmodel,  marker=\"x\", color='red', label='Original frame')\n",
    "plt.xlim([-1.2,1.2])\n",
    "plt.ylim([-1.2,1.2])\n",
    "plt.xlabel(\"$\\Re[C_p]$ Jy/Beam\")\n",
    "plt.ylabel(\"$\\Im[C_p]$ Jy/Beam\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown in the paper the CLEANing is indpendent of the choice of reference frame for the feeds wrt. the sky."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#First simulate Traditional seperate polarization CLEAN on the original unrotated frame:\n",
    "_, _, _, _, TradQ_clean, TradQ_residue, TradQ_restored, TradQ_convmodel, _, _, _, _, _, _, _, _ = CLEAN_HOG(I[ch],Q[ch],U[ch],V[ch],I_PSF[ch],mode=\"Q\")\n",
    "_, _, _, _, _, _, _, _, TradU_clean, TradU_residue, TradU_restored, TradU_convmodel,_, _, _, _ = CLEAN_HOG(I[ch],Q[ch],U[ch],V[ch],I_PSF[ch],mode=\"U\")\n",
    "\n",
    "#Let P = Q + iU, then rotate each complex number by theta:\n",
    "theta = np.deg2rad(65)\n",
    "P = Q[ch] + 1.0j*U[ch]\n",
    "RP = P * np.exp(1.0j * theta)\n",
    "#traditional seperate clean on rotated frame:\n",
    "_, _, _, _, RQ_clean, RQ_residue, RQ_restored, RQ_convmodel, _, _, _, _, _, _, _, _ = CLEAN_HOG(I[ch],RP.real,RP.imag,V[ch],I_PSF[ch],mode=\"Q\")\n",
    "_, _, _, _, _, _, _, _, RU_clean, RU_residue, RU_restored, RU_convmodel,_, _, _, _ = CLEAN_HOG(I[ch],RP.real,RP.imag,V[ch],I_PSF[ch],mode=\"U\")\n",
    "\n",
    "#unrotate the frame:\n",
    "RPClean = RQ_convmodel + 1.0j*RU_convmodel\n",
    "PClean = RPClean * np.exp(1.0j * (-theta))\n",
    "%matplotlib inline\n",
    "plt.figure(1,(5,5))\n",
    "plt.title(\"Traditional seperate polarization CLEAN\")\n",
    "plt.scatter(np.real(PClean),np.imag(PClean), marker=\"+\", color='blue', label='Rotated frame')\n",
    "plt.scatter(TradQ_convmodel,TradU_convmodel,  marker=\"x\", color='red', label='Original frame')\n",
    "plt.xlim([-1.2,1.2])\n",
    "plt.ylim([-1.2,1.2])\n",
    "plt.xlabel(\"$\\Re[C_p]$ Jy/Beam\")\n",
    "plt.ylabel(\"$\\Im[C_p]$ Jy/Beam\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot confirms that Traditional CLEAN is dependent on the Feed reference frame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Joint deconvolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we do joint deconvolution by searching for the peak in the average image (over channels). For realistic data containing noise the averaging procedure should increase the signal to noise ratio.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def give_average_image(I,Q,U,V,mode):\n",
    "    Im = np.zeros_like(I)\n",
    "    Qm = np.zeros_like(Q)\n",
    "    Um = np.zeros_like(U)\n",
    "    Vm = np.zeros_like(V)\n",
    "    if mode == \"I\":\n",
    "        Im = np.mean(I,axis=0)\n",
    "    else:\n",
    "        raise ValueError(\"Joint deconvolution only implemented for mode I\")\n",
    "    return Im, Qm, Um, Vm\n",
    "\n",
    "def give_peak(p,q,Iresidue,Qresidue,Uresidue,Vresidue,mode=\"I\"):\n",
    "    \"\"\"\n",
    "    Finds peak in image or combination of images depending on mode\n",
    "    Q+iU: Luke Pratley's joint linear (P) polarization clean\n",
    "    I: Intensity only\n",
    "    \"\"\"\n",
    "    if mode == \"Q+iU\":\n",
    "        values_map = Qresidue + Uresidue*1.0j\n",
    "        Istar = values_map[:,p,q] #in Q and U the values may be negative or positive\n",
    "    elif mode == \"Q\":\n",
    "        Istar = Qresidue[:,p,q]\n",
    "    elif mode == \"U\":\n",
    "        Istar = Uresidue[:,p,q]\n",
    "    elif mode == \"V\":\n",
    "        Istar = Vresidue[:,p,q]\n",
    "    elif mode == \"I\":\n",
    "        Istar = Iresidue[:,p,q]\n",
    "    else:\n",
    "        raise ValueError(\"Mode not supported\")\n",
    "    return Istar\n",
    "\n",
    "def build_cleanmap_joint(ICLEAN,QCLEAN,UCLEAN,VCLEAN,Istar,gamma,p,q,mode=\"I\"):\n",
    "    if mode == \"Q+iU\":\n",
    "        QCLEAN[:,p,q] += Istar.real*gamma\n",
    "        UCLEAN[:,p,q] += Istar.imag*gamma\n",
    "    elif mode == \"Q\":\n",
    "        QCLEAN[:,p,q] += Istar*gamma\n",
    "    elif mode == \"U\":\n",
    "        UCLEAN[:,p,q] += Istar*gamma\n",
    "    elif mode == \"V\":\n",
    "        VCLEAN[:,p,q] += Istar*gamma\n",
    "    elif mode == \"I\":\n",
    "        ICLEAN[:,p,q] += Istar*gamma\n",
    "    else:\n",
    "        raise ValueError(\"Cleanmap building only works for mode one of [Q+iU, I]\")\n",
    "        \n",
    "def update_residual_joint(Iresidue,Qresidue,Uresidue,Vresidue,Istar,gamma,p,q,PSF,mode=\"I\"):\n",
    "    if mode == \"Q+iU\":\n",
    "        npix = Iresidue.shape[1] #Assuming square image\n",
    "        Qresidue -= gamma*Istar.real[:,np.newaxis,np.newaxis]*PSF[:,npix - p:2*npix - p,\n",
    "                                         npix - q:2*npix - q] \n",
    "        Uresidue -= gamma*Istar.imag[:,np.newaxis,np.newaxis]*PSF[:,npix - p:2*npix - p,\n",
    "                                         npix - q:2*npix - q]\n",
    "    elif mode == \"Q\":\n",
    "        npix = Iresidue.shape[1] #Assuming square image\n",
    "        Qresidue -= gamma*Istar[:,np.newaxis,np.newaxis]*PSF[:,npix - p:2*npix - p,\n",
    "                                    npix - q:2*npix - q] \n",
    "    elif mode == \"U\":\n",
    "        npix = Iresidue.shape[1] #Assuming square image\n",
    "        Uresidue -= gamma*Istar[:,np.newaxis,np.newaxis]*PSF[:,npix - p:2*npix - p,\n",
    "                                    npix - q:2*npix - q] \n",
    "    elif mode == \"V\":\n",
    "        npix = Iresidue.shape[1] #Assuming square image\n",
    "        Vresidue -= gamma*Istar[:,np.newaxis,np.newaxis]*PSF[:,npix - p:2*npix - p,\n",
    "                                    npix - q:2*npix - q] \n",
    "    elif mode == \"I\":\n",
    "        npix = Iresidue.shape[1] #Assuming square image\n",
    "        Iresidue -= gamma*Istar[:,np.newaxis,np.newaxis]*PSF[:,npix - p:2*npix - p,\n",
    "                                    npix - q:2*npix - q] \n",
    "    else:\n",
    "        raise ValueError(\"Mode not supported\")\n",
    "\n",
    "def CLEAN_JOINT(IDIRTY,QDIRTY,UDIRTY,VDIRTY,\n",
    "              PSF,gamma = 0.1,threshold = \"Default\", niter = \"Default\", \n",
    "              plot_on=True, mode=\"I\"):\n",
    "    \"\"\"\n",
    "    This is Hogbom CLEAN assuming a full cleaning window\n",
    "    Input: IDirty = the dirty image to be cleaned\n",
    "    PSF = the point spread function\n",
    "    gamma = the gain factor (must be less than one)\n",
    "    theshold = the threshold to clean up to\n",
    "    niter = the maximum number of iterations allowed\n",
    "    Output: ICLEAN = Clean model, IRESIDUAL = Residuals, \n",
    "            IRESTORE = Restored map, ICONV_CLEAN = Clean model convolved with clean beam\n",
    "    \n",
    "    \"\"\"\n",
    "    nchan = PSF.shape[0]\n",
    "    #deep copy dirties to first residues, want to keep the original dirty maps\n",
    "    ID = np.copy(IDIRTY)\n",
    "    QD = np.copy(QDIRTY) \n",
    "    UD = np.copy(UDIRTY) \n",
    "    VD = np.copy(VDIRTY)\n",
    "    \n",
    "    #Get mean\n",
    "    IDm, QDm, UDm, VDm = give_average_image(ID,QD,UD,VD,mode)\n",
    "    \n",
    "    #Check that all the dirty maps have the same shape\n",
    "    if (ID.shape[0] != QD.shape[0] or QD.shape[0] != UD.shape[0] or UD.shape[0] != VD.shape[0] or\n",
    "        ID.shape[1] != QD.shape[1] or QD.shape[1] != UD.shape[1] or UD.shape[1] != VD.shape[1] or\n",
    "        ID.shape[2] != QD.shape[2] or QD.shape[2] != UD.shape[2] or UD.shape[2] != VD.shape[2]):\n",
    "            raise ValueError(\"Polarized dirties must have the same shape\")\n",
    "    \n",
    "    #Check that PSF is twice the size of ID\n",
    "    if PSF.shape[0] != ID.shape[0] or PSF.shape[1] != 2*ID.shape[1] or PSF.shape[2] != 2*ID.shape[2]:\n",
    "        raise ValueError(\"Warning PSF not right size\")\n",
    "    \n",
    "    #Initialise array to store cleaned image\n",
    "    ICLEAN = zeros([nchan,npix,npix])\n",
    "    QCLEAN = zeros([nchan,npix,npix])\n",
    "    UCLEAN = zeros([nchan,npix,npix])\n",
    "    VCLEAN = zeros([nchan,npix,npix])\n",
    "\n",
    "    #Set max iterations\n",
    "    if niter == \"Default\":\n",
    "        niter = 3*npix\n",
    "\n",
    "    #Find peak in average image\n",
    "    p,q,pmin,qmin,Istarm = find_peak(IDm,QDm,UDm,VDm,mode)\n",
    "\n",
    "    #Set threshold to clean up to (note applied to average map)\n",
    "    if threshold==\"Default\":\n",
    "        threshold = 0.2*np.abs(Istarm) #Imin + 0.001*(Istar - Imin)\n",
    "        print \"Threshold set at \", threshold\n",
    "    else:\n",
    "        print \"Assuming user set threshold\"\n",
    "\n",
    "    #Get Istar for all freqs\n",
    "    Istar = give_peak(p,q,ID,QD,UD,VD,mode)\n",
    "    \n",
    "    #CLEAN the image\n",
    "    i = 0 #counter index\n",
    "    pbar_clean = FloatProgress(min=0, max=100)\n",
    "    display(pbar_clean)\n",
    "\n",
    "    while np.abs(Istarm) > threshold and i <= niter:\n",
    "        #First we set the\n",
    "        build_cleanmap_joint(ICLEAN,QCLEAN,UCLEAN,VCLEAN,Istar,gamma,p,q,mode)\n",
    "        #Subtract out pixel\n",
    "        update_residual_joint(ID,QD,UD,VD,Istar,gamma,p,q,PSF,mode)\n",
    "        #Get averages for peak finding\n",
    "        IDm, QDm, UDm, VDm = give_average_image(ID,QD,UD,VD,mode)\n",
    "        #Get new indices where average image is max\n",
    "        p,q,_,_,Istarm = find_peak(IDm,QDm,UDm,VDm,mode)\n",
    "        Istar = give_peak(p,q,ID,QD,UD,VD,mode)\n",
    "        #Increment counter\n",
    "        i += 1\n",
    "        #Warn if niter exceeded\n",
    "        if i > niter:\n",
    "            print \"Warning: number of iterations exceeded\"\n",
    "            print \"Minimum ID = \", ID.max()\n",
    "        pbar_clean.value = i / float(niter) * 100.0\n",
    "    pbar_clean.value = 100 # done\n",
    "    print \"Done cleaning for mode %s after %d iterations. Now restoring...\" % (mode,i)\n",
    "    \n",
    "    ICONV_MODEL = np.zeros([nchan,npix,npix])\n",
    "    QCONV_MODEL = np.zeros([nchan,npix,npix])\n",
    "    UCONV_MODEL = np.zeros([nchan,npix,npix])\n",
    "    VCONV_MODEL = np.zeros([nchan,npix,npix])\n",
    "    IRESIDUE = ID\n",
    "    QRESIDUE = QD\n",
    "    URESIDUE = UD\n",
    "    VRESIDUE = VD\n",
    "    IRESTORE = np.zeros([nchan,npix,npix])\n",
    "    QRESTORE = np.zeros([nchan,npix,npix])\n",
    "    URESTORE = np.zeros([nchan,npix,npix])\n",
    "    VRESTORE = np.zeros([nchan,npix,npix])\n",
    "    \n",
    "    for i in range(nchan):\n",
    "        #get the ideal beam (fit 2D Gaussian to HWFH of PSF)\n",
    "        CLEAN_BEAM = fit_2D_Gaussian(PSF[i,:,:])\n",
    "\n",
    "        #Now convolve ICLEAN with ideal beam\n",
    "        ICONV_MODEL[i,:,:], QCONV_MODEL[i,:,:], UCONV_MODEL[i,:,:], VCONV_MODEL[i,:,:] = convolve_model(CLEAN_BEAM, ICLEAN[i,:,:], QCLEAN[i,:,:], UCLEAN[i,:,:], VCLEAN[i,:,:], mode)\n",
    "\n",
    "        #Finally we add the residuals back to the image\n",
    "\n",
    "        IRESTORE[i,:,:] = ICONV_MODEL[i,:,:] + IRESIDUE[i,:,:]\n",
    "        QRESTORE[i,:,:] = QCONV_MODEL[i,:,:] + QRESIDUE[i,:,:]\n",
    "        URESTORE[i,:,:] = UCONV_MODEL[i,:,:] + URESIDUE[i,:,:]\n",
    "        VRESTORE[i,:,:] = VCONV_MODEL[i,:,:] + VRESIDUE[i,:,:]\n",
    "    \n",
    "    return (ICLEAN, IRESIDUE, IRESTORE, ICONV_MODEL,QCLEAN, QRESIDUE, QRESTORE, QCONV_MODEL,\n",
    "            UCLEAN, URESIDUE, URESTORE, UCONV_MODEL,VCLEAN, VRESIDUE, VRESTORE, VCONV_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Cleaning I...\"\n",
    "I_clean_j,I_residue_j,I_restored_j,I_convmodel_j, _, _, _, _, _, _, _, _ , _, _, _, _ = CLEAN_JOINT(I,Q,U,V,I_PSF,mode=\"I\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ch = 1\n",
    "F = plt.figure(1,(15,15))\n",
    "grid = ImageGrid(F, 111,  # similar to subplot(111)\n",
    "                nrows_ncols=(2, 2),\n",
    "                direction=\"row\",\n",
    "                axes_pad=0.5,\n",
    "                add_all=True,\n",
    "                label_mode=\"1\",\n",
    "                share_all=True,\n",
    "                cbar_location=\"right\",\n",
    "                cbar_mode=\"each\",\n",
    "                cbar_size=\"3%\")\n",
    "\n",
    "grid[0].set_title(\"I Restored\")\n",
    "im = grid[0].imshow(I_restored_j[ch], interpolation=\"nearest\", cmap=\"cubehelix\")\n",
    "grid[0].cax.colorbar(im)\n",
    "grid[1].set_title(\"I Residue\")\n",
    "im = grid[1].imshow(I_residue_j[ch], interpolation=\"nearest\", cmap=\"cubehelix\")\n",
    "grid[1].cax.colorbar(im)\n",
    "grid[2].set_title(\"I Model\")\n",
    "im = grid[2].imshow(I_clean_j[ch], interpolation=\"nearest\", cmap=\"cubehelix\")\n",
    "grid[2].cax.colorbar(im)\n",
    "grid[3].set_title(\"I convolved clean map\")\n",
    "im = grid[3].imshow(I_convmodel_j[ch], interpolation=\"nearest\", cmap=\"cubehelix\")\n",
    "grid[3].cax.colorbar(im)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Multi-Frequency-Synthesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterative $\\chi^2$ minimisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The imaging problem can be formulated as an iterative $\\chi^2$ minimisation of a system of linear equations of the form\n",
    "$$ Ax = b + \\epsilon,$$\n",
    "where $\\epsilon$ is iid Gaussian noise. This allows us to form the $\\chi^2$ distribution as\n",
    "$$ \\chi^2 = (Ax - b)^\\dagger W (Ax - b), $$\n",
    "where $W$ is a diagonal matrix of weights and the superscript $\\dagger$ denotes the Hermitian conjugate. The assumption that $\\epsilon$ is Gaussian noise is quite important here. Basically it ensures that the quantity we are optimising only has a single stationary point. In contrast, if $\\epsilon$ was not Gaussian but rather some multi-modal distribution, then the quantity $\\epsilon^\\dagger \\epsilon$ could also have a multi-modal distribution. \n",
    "\n",
    "The goal is to find the set of parameters $x$ which minimises $\\chi^2$. The gradient of $\\chi^2$ is given by\n",
    "$$ \\partial_x \\chi^2 = J(x) = A^\\dagger W (b - Ax), $$\n",
    "where we have used the standard linear algebra notation $J(x)$ to denote the Jacobian (or, since $\\chi^2$ is scalar, also the gradient). One more derivative gives the Hessian $H(x)$ as \n",
    "$$ \\partial^2_x \\chi^2 = H = A^\\dagger W A. $$\n",
    "An iterative solution can therefore be obtained from an initial guess, $x_0$ say, using a numerical root finding algorithm such as Newton's method i.e.\n",
    "$$ x_{i+1} = x_i + H^{-1}(x_i) J(x_i) $$\n",
    "Furthermore, setting the gradient to zero produces the normal equations\n",
    "$$ A^\\dagger W A x = A^\\dagger W b$$\n",
    "Note that if the Hessian matrix $H = A^H W A$ was non-singular we could solve for $x$ directly from the normal equations\n",
    "$$ x = \\left( A^\\dagger W A  \\right)^{-1} A^\\dagger W b. $$\n",
    "Unfortunately, because of incomplete $uv$-coverage, in interferometry the Hessian matrix (viz. $(SF)^\\dagger W SF$ see below) will almost always be singular ($S$ is rank deficient). This necessitates an iterative solution. Note that the solution to the normal equations is not, in general, unique. The solution is ambiguous w.r.t. the addition of any vector $\\tilde{x}$ in the null space of the Hessian i.e. $H\\tilde{x} = 0$. The reason for this is that, according to the normal equations, we have\n",
    "$$ H(x + \\tilde{x}) = Hx = A^\\dagger W b, $$\n",
    "regardless of the choice of $\\tilde{x}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imaging as an iterative $\\chi^2$ minimisation problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The imaging problem can be formulated as an iterative $\\chi^2$ minimisation of a system of linear equations of the form\n",
    "$$ S F I = V_{obs} + \\epsilon,$$\n",
    "where $S$ is the degridding operator, $F$ the Fourier transform and $I$ is the image we want to deconvolve. In this case we form the $\\chi^2$ distribution as\n",
    "$$ \\chi^2 = (S F I - V_{obs})^\\dagger W (S F I - V_{obs}), $$\n",
    "where $W$ are the imaging weights. The goal is to find the image $I$ which minimises $\\chi^2$. \n",
    "In this case the gradient is given by\n",
    "$$ \\partial_x \\chi^2 = J(I) = F^\\dagger S^\\dagger W (S F I - V_{obs}), $$\n",
    "and the Hessian is \n",
    "$$ \\partial^2_x \\chi^2 = H = F^\\dagger S^\\dagger W S F. $$\n",
    "\n",
    "An iterative solution can therefore be obtained from an initial guess, $I_{0}$ say, using a numerical root finding algorithm such as Newton's method i.e.\n",
    "$$ I_{i+1} = I_i + g(H^{-1}) J(I_i), $$\n",
    "where $g$ is a function which approximates the operator $H^{-1}$ and can also be used to control the step size. As already mentioned above, the normal equations viz.\n",
    "$$F^\\dagger S^\\dagger W SF I = F^\\dagger S^\\dagger W V_{obs} = I_D $$\n",
    "where $I_D$ denotes the dirty image, can't be inverted for $I$ in a straighforward manner and we need to use the iterative approach. In imaging the iterative solution is usually implemented using major and minor cycles. Lets see how this works. Firstly, note that, for a given model image $I^{M}$, the Jacobian is just the residual image i.e. \n",
    "$$ J(I^{M}) = F^\\dagger S^\\dagger W (S F I^M - V_{obs}) = I^{R}. $$\n",
    "Thus one iteration of the optimisation method would be given by \n",
    "$$ I^M_{i+1} = I^M_{i} + g(H^{-1}) I^R_{i}. $$\n",
    "The fact that $H$ is singular makes this step a bit tricky to implement directly. Recall that the solution $H^{-1} I^R$ represents a deconvolution of $I^{PSF} * I$. The solution can be approximated via the function $g(\\cdot)$ but, in general, this requires a number of assumptions. We will not go into the details but simply outline how the function is constructed. Assuming that the PSF's are delta functions results in a diagonal Hessian matrix. If they are also spatially invariant then all the elements on the diagonal are the same. Thus the Hessian reduces to a single number viz. the value of the PSF at the center (note we are assuming that neither the residual image nor the PSF has been normalised). We can then start building up the model image by searching for the peak in $I^R$, multiplying by $g(H^{-1})$ (equivalently normalising $I^R$ by the value of the PSF at the center) and adding the result to $I^M$. We can then compute the new residual image (i.e. re-evaluate the Jacobian) and repeating until some prespecified convergence criterion has been reached. \n",
    "\n",
    "Since evaluating the Jacobian is an expensive operation, the algorithm is usually implemented slightly differently. This is where the distinction between minor and major cycles comes in. Major cycles evaluate the Jacobian while minor cycles build up the model image. It is impractical to, within any given minor cycle, build the model image one pixel at a time. To speed things up a bit we might want to add multiple pixels (the brightest ones) to the model image during the minor cycle. This requires performing the subtraction (equivalently computing the Jacobian) in the image domain and can be implemented approximately by subtracting the PSF centered at the location of the current brightest pixel from the entire image. For such an approach it is also advantages to normalise both $I^R$ and $I^{PSF}$ by the value of the PSF at the center. In this case the intensities in $I^D$ (i.e. the first residual image) corresponde to those of $I^M$. Below we give a quick and dirty implementation of this iterative optimisation algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def CLEAN_CS(Vobs,lmn,K,invK,PSF,\n",
    "             gamma = 0.1,threshold = \"Default\", nminoriter = 50,\n",
    "             nmajoriter = 20):\n",
    "    \"\"\"\n",
    "    This is a basic CLEAN implemented using major and minor cycles. \n",
    "    Input:  Vobs = precalibrated visibilities\n",
    "            lmn = the coordinates of the image\n",
    "            K = the DFT kernel\n",
    "            invK = the inverse DFT kernel\n",
    "            PSF = the unnormalised PSF\n",
    "    \"\"\"\n",
    "    #Initialise model image\n",
    "    n = Vobs.shape[0]\n",
    "    Vobs = Vobs.reshape(n,1)\n",
    "    npix = int(np.sqrt(K.shape[1]))\n",
    "    m = npix*npix\n",
    "    IM = np.zeros([npix,npix])\n",
    "    \n",
    "    #Normalise PSF keeping track of maximum\n",
    "    PSF_max = np.max(PSF)\n",
    "    PSF /= PSF_max\n",
    "    \n",
    "    #Get dirty image\n",
    "    print \"Doing iDFT\"\n",
    "    ncoord = (lmn[:,-1] + 1.0).reshape(m,1)\n",
    "    ID = np.real(ncoord*np.dot(invK,Vobs)/PSF_max).reshape(npix,npix) #ncoord*\n",
    "    print ID.shape\n",
    "    \n",
    "    #Find first maximum\n",
    "    p,q = (argwhere(ID == ID.max())[0]).squeeze()\n",
    "    Istar = ID[p,q]\n",
    "    \n",
    "    #Set threshold\n",
    "    if threshold==\"Default\":\n",
    "        threshold = 0.1*np.abs(Istar) #Imin + 0.001*(Istar - Imin)\n",
    "        print \"Threshold set at \", threshold\n",
    "    else:\n",
    "        print \"Assuming user set threshold\"\n",
    "        \n",
    "    #Start deconvolution\n",
    "    i = 0\n",
    "    cont = True\n",
    "    IR = ID.copy()\n",
    "    while (i < nmajoriter) and cont:\n",
    "        #Enter minor cycle\n",
    "        j = 0\n",
    "        while (j < nminoriter) and (Istar > threshold):\n",
    "            #Update model image\n",
    "            IM[p,q] += gamma*Istar\n",
    "            \n",
    "            #Do image plane subtraction\n",
    "            IR -= gamma*Istar*PSF[npix - p:2*npix - p,npix - q:2*npix - q] \n",
    "    \n",
    "            #Get new indices where IR is max\n",
    "            p,q = (argwhere(IR == IR.max())[0]).squeeze()\n",
    "            Istar = IR[p,q] \n",
    "            \n",
    "            #Increment minor cycle counter\n",
    "            j += 1 \n",
    "        #Increment major cycle counter\n",
    "        i += 1\n",
    "        print i\n",
    "        #Get residual image and check convergence criterion\n",
    "        IR = get_Jacobian(Vobs,IM,K,invK,ncoord,npix,PSF_max)\n",
    "        p,q = (argwhere(IR == IR.max())[0]).squeeze()\n",
    "        Istar = IR[p,q]        \n",
    "        if Istar < threshold:\n",
    "            cont = False\n",
    "            \n",
    "    #Warn if number of iterations exceed\n",
    "    if i >= nmajoriter:\n",
    "        print \"Max iterations exceeded. Istar = \",Istar\n",
    "\n",
    "    return IM\n",
    "    \n",
    "    \n",
    "def get_Jacobian(Vobs,IM,K,invK,ncoord,npix,PSF_max):\n",
    "    #Apply DFT to I\n",
    "    Vpred = np.dot(K,IM.reshape(npix*npix,1)/ncoord)\n",
    "    \n",
    "    #Get residual vis\n",
    "    Vres = Vobs - Vpred\n",
    "    \n",
    "    #Get IR\n",
    "    IR = np.real(ncoord*np.dot(invK,Vres)/PSF_max)\n",
    "    return IR.reshape(npix,npix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Here we do the CS CLEAN over a single channel\n",
    "#Load in MS\n",
    "ms = tbl(\"DATA/polarized_sky.MS_p0/\")\n",
    "\n",
    "#Get freq info\n",
    "msfreq = tbl(\"DATA/polarized_sky.MS_p0::SPECTRAL_WINDOW\")\n",
    "\n",
    "#Get pointing center\n",
    "msfield = tbl(\"DATA/polarized_sky.MS_p0::FIELD\")\n",
    "ra0, dec0 = msfield.getcol(\"PHASE_DIR\").squeeze() #in radians\n",
    "\n",
    "#Some constants and conversion factors\n",
    "c = 2.99792458e8 #speed of light\n",
    "npix = 128 #1025\n",
    "ARCSEC2RAD = 4.8481e-6\n",
    "delta_pix = 2 * ARCSEC2RAD * 2 * 2 * 2 \n",
    "uv_scale = npix * delta_pix\n",
    "\n",
    "#Select subset of data\n",
    "nchan = 5 #-1 to select all (NOTE this selects all but the last)\n",
    "nrows = 1000 #-1 to select all\n",
    "uvw = ms.getcol(\"UVW\")[0:nrows,:] \n",
    "vis = ms.getcol(\"DATA\")[0:nrows,0:nchan,:]\n",
    "#Delete autocorelations\n",
    "I = np.argwhere(uvw[:,0] == 0.0).squeeze()\n",
    "uvw = np.delete(uvw,I,axis=0)\n",
    "scaled_uvw = uvw * uv_scale\n",
    "vis = np.delete(vis,I,axis=0)\n",
    "\n",
    "#Get frequencies\n",
    "Freqs = msfreq.getcol(\"CHAN_FREQ\").squeeze()[0:nchan]\n",
    "ref_freq = Freqs[0]\n",
    "\n",
    "#Close tables\n",
    "ms.close()\n",
    "msfreq.close()\n",
    "msfield.close()\n",
    "\n",
    "#Get wavelengths\n",
    "ref_lambda = c / Freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Set ra and dec\n",
    "ra = ra0 + np.linspace(ra0 - npix*delta_pix/2.0,ra0 + npix*delta_pix/2.0,npix)\n",
    "#ra_PSF  = ra0 + np.linspace(ra0 - npix*delta_pix,ra0 + npix*delta_pix,2*npix)\n",
    "delta_ra = ra - ra0\n",
    "#delta_ra_PSF = ra_PSF - ra0\n",
    "dec = dec0 + np.linspace(dec0 - npix*delta_pix/2.0,dec0 + npix*delta_pix/2.0,npix)\n",
    "#dec_PSF = dec0 + np.linspace(dec0 - npix*delta_pix,dec0 + npix*delta_pix,2*npix)\n",
    "\n",
    "#Get corresponding l and m\n",
    "l = (np.cos(dec)*np.sin(delta_ra))\n",
    "#l_PSF = (np.cos(dec_PSF)*np.sin(delta_ra_PSF))\n",
    "m = (-np.sin(dec)*np.cos(dec0) - np.cos(dec)*np.sin(dec0)*cos(delta_ra))\n",
    "#m_PSF = (-np.sin(dec_PSF)*np.cos(dec0) - np.cos(dec_PSF)*np.sin(dec0)*cos(delta_ra_PSF))\n",
    "\n",
    "print \"Getting lmn\"\n",
    "lmn = get_lmn(l,m)\n",
    "n = lmn[:,2] + 1.0\n",
    "#lmn_PSF = get_lmn(l_PSF,m_PSF)\n",
    "#n_PSF = lmn_PSF[:,2] + 1.0\n",
    "\n",
    "#print \"Getting DFT kernels for PSF\"\n",
    "#invK_PSF = set_kernels(2*npix,2*npix,lmn_PSF,uvw,ref_lambda)\n",
    "\n",
    "#print \"Computing PSF\"\n",
    "#PSF = iDFT(np.ones([vis.shape[0],nchan]),invK_PSF,n_PSF) #np.abs(dot(invK[0,:,:],np.ones(vis.shape[0])))\n",
    "#PSF = np.abs(PSF.reshape(nchan,2*npix,2*npix))\n",
    "#PSF0 = PSF[0]\n",
    "\n",
    "#del(invK_PSF)\n",
    "#del(l_PSF)\n",
    "#del(m_PSF)\n",
    "#del(lmn_PSF)\n",
    "#del(n_PSF)\n",
    "\n",
    "print \"Getting DFT kernels\"\n",
    "K = set_kernels(npix,npix,lmn,uvw,ref_lambda)\n",
    "#invK0 = invK[0]\n",
    "#K0 = invK0.conjugate().T\n",
    "#K = np.zeros([nchan,uvw.shape[0],npix*npix],dtype=complex)\n",
    "#for i in range(nchan):\n",
    "#    K[i,:,:] = invK[i,:,:].conjugate().T\n",
    "\n",
    "#Get V corresponding to stokes I \n",
    "Vobs = (vis[:,:,0] + vis[:,:,3])*0.5\n",
    "\n",
    "#Create gridder object\n",
    "gridder = grid_it(scaled_uvw,ref_lambda,npix,npix,aa)\n",
    "\n",
    "print \"Done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Doing CS CLEAN\"\n",
    "IM = CLEAN_CS(Vobs[:,0].copy(),lmn,K[0].copy(),invK[0].copy(),PSF[0].copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(IM,interpolation=\"nearest\", cmap=\"cubehelix\")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MFS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by Taylor expanding the model image $I^M(\\nu)$ into \n",
    "$$ I^M(\\nu) = \\sum_{t=0}^{N_t-1} w(\\nu)^t I^T_t, $$\n",
    "where $I^T_t = \\frac{d^t}{d \\nu^t}I^M(\\nu)|_{\\nu = \\nu_0}$ is the $t^{th}$ Taylor coefficient and $w(\\nu) = \\left(\\frac{\\nu - \\nu_0}{\\nu_0}\\right)$ can be thought of as basis functions. Substitute this into the expression for $V^{obs}$ to find\n",
    "$$ V^{obs}_\\nu = \\sum_{t = 0}^{N_t-1} w(\\nu)^t S_\\nu F I^T_t = \n",
    "\\left[ \\begin{array}{cccc}\n",
    "[ w^0_v S_v F] & [ w^1_v S_v F] & \\cdot & \\cdot\n",
    "\\end{array} \\right] \\left[\\begin{array}{c} I^T_0 \\\\ I^T_1 \\\\ \\cdot \\\\ \\cdot \\end{array} \\right], $$\n",
    "where in the last step we perform the summation using block matrices. MFS basically works by using all the visibility data (i.e. in each channel/band) to estimate the Taylor components $I^T$. This can be achieved by solving the following system\n",
    "$$\n",
    "\\left[ \\begin{array}{cccc}\n",
    "[ w^0_{v_1} S_{v_1} F] & [ w^1_{v_1} S_{v_1} F] & \\cdot & \\cdot \\\\\n",
    "[ w^0_{v_2} S_{v_2} F] & [ w^1_{v_2} S_{v_2} F] & \\cdot & \\cdot \\\\\n",
    "\\cdot & \\cdot & \\cdot & \\cdot\n",
    "\\end{array} \\right] \\left[\\begin{array}{c} I^T_0 \\\\ I^T_1 \\\\ \\cdot \\\\ \\cdot \\end{array} \\right] = \\left[\\begin{array}{c} V^{obs}_{\\nu_1} \\\\ V^{obs}_{\\nu_2} \\\\ \\cdot \\\\ \\cdot \\end{array} \\right].\n",
    "$$\n",
    "The normal equations for this system can be found simply by multiplying through by the Hermitian conjugate of the matrix on the left\n",
    "$$\n",
    "\\left[ \\begin{array}{ccc}\n",
    "[ w^0_{v_1} S^\\dagger_{v_1} F^\\dagger] & [w^0_{v_2} S^\\dagger_{v_2} F^\\dagger] & \\cdot \\\\\n",
    "[ w^1_{v_1} S^\\dagger_{v_1} F^\\dagger] & [ w^1_{v_2} S^\\dagger_{v_2} F^\\dagger] & \\cdot \\\\\n",
    "\\cdot & \\cdot & \\cdot  \\\\\n",
    "\\cdot & \\cdot & \\cdot \n",
    "\\end{array} \\right]\n",
    "\\left[ \\begin{array}{cccc}\n",
    "[ w^0_{v_1} S_{v_1} F] & [ w^1_{v_1} S_{v_1} F] & \\cdot & \\cdot \\\\\n",
    "[ w^0_{v_2} S_{v_2} F] & [ w^1_{v_2} S_{v_2} F] & \\cdot & \\cdot \\\\\n",
    "\\cdot & \\cdot & \\cdot & \\cdot\n",
    "\\end{array} \\right] \\left[\\begin{array}{c} I^T_0 \\\\ I^T_1 \\\\ \\cdot \\\\ \\cdot \\end{array} \\right] = \n",
    "\\left[ \\begin{array}{ccc}\n",
    "[ w^0_{v_1} S^\\dagger_{v_1} F^\\dagger] & [w^0_{v_2} S^\\dagger_{v_2} F^\\dagger] & \\cdot \\\\\n",
    "[ w^1_{v_1} S^\\dagger_{v_1} F^\\dagger] & [ w^1_{v_2} S^\\dagger_{v_2} F^\\dagger] & \\cdot \\\\\n",
    "\\cdot & \\cdot & \\cdot  \\\\\n",
    "\\cdot & \\cdot & \\cdot \n",
    "\\end{array} \\right]\n",
    "\\left[\\begin{array}{c} V^{obs}_{\\nu_1} \\\\ V^{obs}_{\\nu_2} \\\\ \\cdot \\\\ \\cdot \\end{array} \\right].\n",
    "$$\n",
    "or\n",
    "$$ H I^T = I, $$\n",
    "where the images on the RHS are constructed from $I^D_{\\nu}$ according to\n",
    "$$ I_i = \\sum_{\\nu_k} w_{\\nu_k}^i S^\\dagger_{v_k} F^\\dagger V^{obs}_{\\nu_k} = \\sum_{\\nu_k} w_{\\nu_k}^i I^D_{\\nu_k}, $$\n",
    "and the Hessian matrix consists of block matrices of the following form\n",
    "$$ H_{ij} = \\sum_{\\nu_k} w_{\\nu_k}^{i+j} F^\\dagger S^\\dagger_{\\nu_k} S_{\\nu_k} F. $$ \n",
    "The solution to the normal equations therefore provides the Taylor components $I^T$. The full Hessian matrix will not, in general, be invertible. However, by making the same assumptions as before, we can reduce each $H_{ij}$ to a single number viz. \n",
    "$$ H_{ij} = \\sum_{\\nu_k} w_{\\nu_k}^{i + j} \\mbox{mid}(I^{PSF}_{\\nu_k}). $$\n",
    "The deconvolution can be approximated by searching for the peak in $I_0$ (since $I_0 = \\sum_{\\nu_k} I^D_{\\nu_k}$ this is similar to searching the average image as is done in joint deconvolution) and computing $I^T$ using\n",
    "$$ I^T = H^{-1}I $$\n",
    "These can now be used to compute the predicted visibilities required to compute the Jacobian in the major cycle. Subtraction within the image domain is slightly trickier. We have to get\n",
    "$$ I^M(\\nu) = \\sum_{t=0}^{N_t-1} w(\\nu)^t I^T_t $$\n",
    "for each frequency and subtract $I^M * I^{PSF}$ from $I^D$ and use the updated $I^D$ to again get $I$ (there might be a simpler way to do this). \n",
    "\n",
    "Assuming a spectral index model\n",
    "$$ I^M(v) = I^M_0 (\\frac{\\nu}{\\nu_0})^\\alpha $$\n",
    "shows that\n",
    "$$ I^T_0 = I^M_0, \\quad I^T_1 = \\alpha I^M_0, $$\n",
    "so that we get an alpha map from\n",
    "$$ \\alpha = \\frac{I^T_1}{I^T_0}. $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def CLEAN_MFS(Vobs,lmn,K,ID,PSF,Nt,Freqs,ref_freq,gridder,\n",
    "             gamma = 0.25,threshold = \"Default\", nminoriter = 10,\n",
    "             nmajoriter = 100):\n",
    "    \"\"\"\n",
    "    This is a basic MFS CLEAN implemented using major and minor cycles. \n",
    "    Input:  Vobs = precalibrated visibilities\n",
    "            lmn = the coordinates of the image\n",
    "            K = the DFT kernel\n",
    "            invK = the inverse DFT kernel\n",
    "            PSF = the unnormalised PSF\n",
    "    \"\"\"\n",
    "    #Initialise model image\n",
    "    n = Vobs.shape[0]\n",
    "    nchan = Vobs.shape[1]\n",
    "    npix = int(np.sqrt(K.shape[2]))\n",
    "    m = npix*npix\n",
    "    IT = np.zeros([Nt,npix,npix])\n",
    "    IM = np.zeros([nchan,npix,npix])\n",
    "    \n",
    "    #Normalise PSF keeping track of maximum\n",
    "    PSF_max = np.zeros(nchan)\n",
    "    for i in xrange(nchan):\n",
    "        PSF_max[i] = np.max(PSF[i])\n",
    "        PSF[i] /= PSF_max[i]\n",
    "    print PSF_max\n",
    "    #Get dirty image\n",
    "    print \"Getting Dirty cube\"\n",
    "    ncoord = (lmn[:,-1] + 1.0).reshape(m,1)\n",
    "\n",
    "    #Compute weighted sum of dirty's\n",
    "    print \"Getting I from ID\"\n",
    "    I = set_Dirty_Comps(ID,Freqs,ref_freq,Nt)\n",
    "    \n",
    "    Itmp = I[0] #this is where we do the peak finding\n",
    "    \n",
    "    #Find first maximum\n",
    "    p,q = (argwhere(Itmp == Itmp.max())[0]).squeeze()\n",
    "    Istarm = Itmp[p,q]\n",
    "    \n",
    "    #Set the Hessian and get inverse\n",
    "    print \"Setting H\"\n",
    "    H = set_Hessian(PSF_max,Freqs,ref_freq,Nt,nchan)\n",
    "    invH = np.linalg.inv(H)\n",
    "    print invH\n",
    "    \n",
    "    #Solve for Taylor components\n",
    "    Istar = np.dot(invH,I[:,p,q])\n",
    "    \n",
    "    #Set threshold\n",
    "    if threshold==\"Default\":\n",
    "        threshold = 0.2*np.abs(Istarm) \n",
    "        print \"Threshold set at \", threshold\n",
    "    else:\n",
    "        print \"Assuming user set threshold\"\n",
    "        \n",
    "    #Start deconvolution\n",
    "    i = 0\n",
    "    IR = ID.copy()\n",
    "    print \"Deconvolving\"\n",
    "    while (i < nmajoriter) and (Istarm > threshold):\n",
    "        #Increment major cycle counter\n",
    "        i += 1\n",
    "        if i%10 == 0:\n",
    "            print i, Istarm, Istar.max()\n",
    "        \n",
    "        #Update IT\n",
    "        IT[:,p,q] += gamma*Istar\n",
    "        \n",
    "        #Get residual image\n",
    "        IR, I = get_Jacobian_MFS(Vobs,IT,K,ncoord,npix,PSF_max,Freqs,ref_freq,gridder)\n",
    "        \n",
    "        #Find next peak\n",
    "        Itmp = I[0]\n",
    "        p,q = (argwhere(Itmp == Itmp.max())[0]).squeeze()\n",
    "        Istarm = Itmp[p,q]\n",
    "        \n",
    "        #get IT\n",
    "        Istar = np.dot(invH,I[:,p,q])\n",
    "    \n",
    "            \n",
    "    #Warn if number of iterations exceeded\n",
    "    if i >= nmajoriter:\n",
    "        print \"Max iterations exceeded. Istar = \",Istarm\n",
    "    \n",
    "    print \"Done\"\n",
    "    \n",
    "    #Get IM\n",
    "    w = (Freqs - ref_freq)/ref_freq\n",
    "    for k in xrange(nchan):\n",
    "        for l in xrange(Nt):\n",
    "            IM[k] += w[k]**l*IT[l] #/mp.factorial(l)\n",
    "    \n",
    "    #Get alpha and beta maps\n",
    "    alpha = IT[1]/IT[0]\n",
    "    return IT, IM, ID, IR, alpha\n",
    "\n",
    "def get_Jacobian_MFS(Vobs,IT,K,ncoord,npix,PSF_max,Freqs,ref_freq,gridder):\n",
    "    #Get number of channels/bands\n",
    "    n = Vobs.shape[0]\n",
    "    nchan = Freqs.size\n",
    "    Nt = IT.shape[0]\n",
    "    \n",
    "    #Apply weighted DFT to each IT\n",
    "    Vpred = np.zeros_like(Vobs)\n",
    "    w = (Freqs - ref_freq)/ref_freq\n",
    "    for i in xrange(nchan):\n",
    "        for j in xrange(Nt):\n",
    "            Vpred[:,i] += w[i]**j*np.dot(K[i],IT[j].reshape(npix*npix,1)/ncoord).squeeze()\n",
    "                \n",
    "    #Get residual vis\n",
    "    Vres = Vobs - Vpred\n",
    "    \n",
    "    #Get residual image\n",
    "    IR = np.real(gridder.give_IR(Vres))\n",
    "    \n",
    "    #Get I\n",
    "    I = set_Dirty_Comps(IR,Freqs,ref_freq,Nt)\n",
    "    return IR, I\n",
    "\n",
    "def set_Hessian(PSF_max,Freqs,ref_freq,Nt,nchan):\n",
    "    \"\"\"\n",
    "    Constructs principal components of the Hessian\n",
    "    \"\"\"\n",
    "    #Create array to store Hessian\n",
    "    H = np.zeros([Nt,Nt])\n",
    "    #Set basis function\n",
    "    w = (Freqs - ref_freq) / ref_freq\n",
    "    #Compute Hessian\n",
    "    for i in xrange(Nt):\n",
    "        for j in xrange(Nt):\n",
    "            tmp = 0.0\n",
    "            for k in range(nchan): \n",
    "                tmp += w[k]**(i+j)*PSF_max[k]\n",
    "            H[i,j] = tmp\n",
    "    return np.diag(np.diag(H))\n",
    "\n",
    "def set_Dirty_Comps(ID,Freqs,ref_freq,Nt):\n",
    "    nchan,nx,ny = ID.shape\n",
    "    I = np.zeros([Nt,nx,ny])\n",
    "    tmp = np.zeros([nx,ny])\n",
    "    w = (Freqs - ref_freq) / ref_freq\n",
    "    for t in xrange(Nt):\n",
    "        for i in xrange(nchan):\n",
    "            tmp += w[i]**t*ID[i,:,:]\n",
    "        I[t,:,:] = tmp\n",
    "    return I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Nt = 3\n",
    "IT, IM, ID, IR, alpha = CLEAN_MFS(Vobs.copy(),lmn.copy(),K.copy(),ID2.copy(),psf2.copy(),Nt,Freqs,ref_freq,gridder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(IT[2],interpolation=\"nearest\", cmap=\"cubehelix\")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "        #Enter minor cycle\n",
    "        j = 0\n",
    "        while (j < nminoriter) and (Istarm > threshold):\n",
    "            #Update model image\n",
    "            IM[:,p,q] += gamma*Istar\n",
    "            \n",
    "            #Do image plane subtraction\n",
    "            IR -= gamma*Istar[:,np.newaxis,np.newaxis]*PSF[:,npix - p:2*npix - p,npix - q:2*npix - q] \n",
    "            \n",
    "            #Get new I\n",
    "            I = set_Dirty_Comps(IR,Freqs,ref_freq,Nt)\n",
    "            Itmp = I[0]\n",
    "            \n",
    "            #Get new indices where I is max\n",
    "            p,q = (argwhere(Itmp == Itmp.max())[0]).squeeze()\n",
    "            Istarm = Itmp[p,q]\n",
    "            \n",
    "            #Solve of IT\n",
    "            IT = np.dot(invH,I[:,p,q])\n",
    "            \n",
    "            for k in xrange(nchan):\n",
    "                for l in xrange(Nt):\n",
    "                    Istar[k] += w[k]**l*IT[l]\n",
    "            \n",
    "            #Increment minor cycle counter\n",
    "            j += 1 \n",
    "\n",
    "            \n",
    "def get_Jacobian_MFS(Vobs,IM,K,invK,ncoord,npix,PSF_max,Freqs,ref_freq):\n",
    "    #Get number of channels/bands\n",
    "    n = Vobs.shape[0]\n",
    "    nchan = Freqs.size\n",
    "    \n",
    "    #Apply weighted DFT to each IM\n",
    "    Vpred = np.zeros_like(Vobs)\n",
    "    for i in xrange(nchan):\n",
    "            Vpred[:,i] = np.dot(K[i],IM[i].reshape(npix*npix,1)/ncoord).squeeze()\n",
    "                \n",
    "    #Get residual vis\n",
    "    Vres = Vobs - Vpred\n",
    "    \n",
    "    #Get IR\n",
    "    IR = np.zeros([nchan,npix,npix])\n",
    "    for i in xrange(nchan):\n",
    "        IR[i] = np.real(ncoord*np.dot(invK[i],Vres[:,i].reshape(n,1))/PSF_max[i]).reshape(npix,npix)\n",
    "    \n",
    "    #Get I\n",
    "    I = set_Dirty_Comps(IR,Freqs,ref_freq,Nt)\n",
    "    return IR, I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def diag_dot(A,B):\n",
    "    D = np.zeros(A.shape[0],dtype=complex)\n",
    "    for i in range(A.shape[0]):\n",
    "        D[i] = dot(A[i,:],B[:,i])\n",
    "    return D    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Nt = 3\n",
    "nchan = 5\n",
    "w = (Freqs - ref_freq)/ref_freq\n",
    "H = np.zeros([Nt,Nt])\n",
    "PSF_max = np.zeros(nchan)\n",
    "for i in range(nchan):\n",
    "    PSF_max[i] = np.abs(diag_dot(K[i],invK[i])).max()\n",
    "\n",
    "for i in range(Nt):\n",
    "    for j in range(Nt):\n",
    "        tmp = 0.0\n",
    "        for k in range(nchan):\n",
    "            tmp += w[k]**(i+j)*PSF_max[k]\n",
    "        H[i,j] = tmp\n",
    "\n",
    "print PSF_max        \n",
    "print np.linalg.inv(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print lmn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Freqs = ref_freq\n",
    "ref_freq = Freqs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "widgets": {
   "state": {
    "06094f5b5b9146a887fc259440d27d7d": {
     "views": [
      {
       "cell_index": 28
      }
     ]
    },
    "0e6f022a331643799752cf5ddf4f289b": {
     "views": []
    },
    "0ff033f742de4f61be49c573d1bf6a54": {
     "views": []
    },
    "1460b85304e445c9a3b87d58e8f99acd": {
     "views": [
      {
       "cell_index": 27
      }
     ]
    },
    "1918f83f881c4ddcb329039ca32729c5": {
     "views": []
    },
    "1dd0a0ad0cab48f8b624c9613cc48bdc": {
     "views": []
    },
    "21a93da426764f528482ccee488b919e": {
     "views": []
    },
    "24a01434ed8f4380bbcdc459cb7d0423": {
     "views": []
    },
    "2766bad045ca4157a9b7c77d3049b40e": {
     "views": [
      {
       "cell_index": 28
      }
     ]
    },
    "29164b61f2b1424d8a5c40eff516c204": {
     "views": []
    },
    "2a7fd2033ef64028bbed6f77097906ba": {
     "views": []
    },
    "30848bec31774c2da4eb13d5a74c3d6d": {
     "views": []
    },
    "33c284240d9d4bc18e2a733b93b81721": {
     "views": [
      {
       "cell_index": 28
      }
     ]
    },
    "3457590f11bd44fe873dd59a6e6ad261": {
     "views": []
    },
    "3716d06a7f974e50ac8e9c39b4163baa": {
     "views": []
    },
    "3786c689d52a46e0b28df96c1b1bfa25": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "389ec5083a05499f9782f9e0d3eaafe0": {
     "views": []
    },
    "39f8130b342f413495d94496dece46f4": {
     "views": []
    },
    "3ce517e808c54431820b6f2a64ff59d5": {
     "views": []
    },
    "3f4bd3e3dd1947c08d0b5b47d52e5e72": {
     "views": []
    },
    "3f4fc117c2b947f397eb47e92c3adf05": {
     "views": []
    },
    "41a20e60562a4bc4b2c942e3d11520e2": {
     "views": [
      {
       "cell_index": 27
      }
     ]
    },
    "41d9dded5ba2440c82eebb6748ba6fb2": {
     "views": []
    },
    "4442ba8eae0944569ba856b74d459010": {
     "views": []
    },
    "451e0fa0f99c44c5a52c14d0699c22cb": {
     "views": []
    },
    "454d077db5e9491d917edadb9c6a7be0": {
     "views": []
    },
    "4696617933d4451291ba862fcc71f974": {
     "views": [
      {
       "cell_index": 28
      }
     ]
    },
    "480d26c071f74d2d9cc60fed9d2c38cf": {
     "views": []
    },
    "4b3f14cc573c4e48a74582cd28200529": {
     "views": [
      {
       "cell_index": 17
      }
     ]
    },
    "4cf4cbb4f6d845e6a0c5e68fdeffa34e": {
     "views": []
    },
    "4ed7aea4c3e641a1a4655dd690be1fe4": {
     "views": []
    },
    "507c021f798c4b89a2f0de874807901d": {
     "views": [
      {
       "cell_index": 26
      }
     ]
    },
    "52c636eb8e184acfa4cd526818a6fe76": {
     "views": []
    },
    "545b89a29c7b4f389c38a61d0a40ed0a": {
     "views": []
    },
    "5630b072cb844e83859ee3fe28e1617f": {
     "views": [
      {
       "cell_index": 27
      }
     ]
    },
    "56dedc8879aa493ca40e7635a623a67a": {
     "views": []
    },
    "57cb78e77d4546edb771f2f873b04096": {
     "views": [
      {
       "cell_index": 28
      }
     ]
    },
    "5913607d7dd04a7e9e44f3286b9a0c99": {
     "views": []
    },
    "5a9221352f424be78bd0472faa23145b": {
     "views": []
    },
    "5b1fb011c98047689b489509a92b8307": {
     "views": [
      {
       "cell_index": 28
      }
     ]
    },
    "611d411cb62c4dc6b9f510089abd8c8f": {
     "views": []
    },
    "62d8b5848b894cc9b5cb0a7d12aadec9": {
     "views": []
    },
    "63a2a2dacae5496bb9762e2ff053bca4": {
     "views": []
    },
    "642a7c7713da4980958e20c221ad8899": {
     "views": []
    },
    "6520c159ae224235842d2753e664ec4e": {
     "views": []
    },
    "679c55427f0a4e008b9e3c67a8d79c2f": {
     "views": []
    },
    "698d3c6d6f8840db8d8568e0613c26f2": {
     "views": [
      {
       "cell_index": 28
      }
     ]
    },
    "6a2fe8ee730a4051920d6fed203af7ef": {
     "views": [
      {
       "cell_index": 17
      }
     ]
    },
    "6ca8915952b04f7690f0dbc0f0af947c": {
     "views": []
    },
    "6edbf7ac79e84ca2a91cfa1b82b21af0": {
     "views": []
    },
    "6f1b4b12eef242979a82e9ea6a630726": {
     "views": []
    },
    "6faccd73ed3f4058a99ced9430941a94": {
     "views": []
    },
    "7093beb220084b0fa4a26c2c0e81d3ed": {
     "views": []
    },
    "71c8b8ce3124485fa022bd290ce2e8d7": {
     "views": []
    },
    "74120a917a66451ba454e0c23c54aace": {
     "views": []
    },
    "7693e82939844ac4b6ad92c47bc2f26c": {
     "views": []
    },
    "76cdbf71fc804b7294b2c00804a1ba51": {
     "views": []
    },
    "7b230864f90043fca731b8343319a9f5": {
     "views": [
      {
       "cell_index": 17
      }
     ]
    },
    "7c00825ce63146c9a7e7d3f33ab020de": {
     "views": [
      {
       "cell_index": 28
      }
     ]
    },
    "7cb5cf1f28f14d0881463ce8599ec494": {
     "views": []
    },
    "7d3d04543524448e91709f31223638da": {
     "views": []
    },
    "7d63b67ee8ab4387ae828b83e0120ba4": {
     "views": []
    },
    "7d7ceb4c16d84b47bae103d933cfb8c5": {
     "views": []
    },
    "7deb3d6d84d945539e2e00bf66d531f7": {
     "views": []
    },
    "7f506fae2fee41059a4b4f3178debc55": {
     "views": [
      {
       "cell_index": 28
      }
     ]
    },
    "80219188f41545b9bee40eae09eec56c": {
     "views": []
    },
    "8283423bfd2a475b92e1fe67d9fb1c86": {
     "views": []
    },
    "8422830fc7b3463fa6ccaa511cf7cd9b": {
     "views": []
    },
    "86c8cc780fa040c48ff27867ceac15ad": {
     "views": []
    },
    "874ea9bed98f4243abf28370b59ab8dd": {
     "views": []
    },
    "8a71c5bea72848049da96bddbb3ca4b8": {
     "views": []
    },
    "8b03c425de0246948cf32ff26fc2f1fc": {
     "views": []
    },
    "8cda9779cd4b43bbbb9ba4a91e67a244": {
     "views": []
    },
    "8fba93039595459fa8059701f4488d22": {
     "views": []
    },
    "94e062a287d34c14b66bcc3d4869a4d4": {
     "views": []
    },
    "950066a790074a3b8e271a0fc15746d0": {
     "views": []
    },
    "95f29ee1f9a24d178bd54b47ddc23922": {
     "views": [
      {
       "cell_index": 27
      }
     ]
    },
    "9902bb057f2a4191ac8bafd0803e4988": {
     "views": [
      {
       "cell_index": 28
      }
     ]
    },
    "9a637091215d48038eab4cf0b83615d8": {
     "views": []
    },
    "9c564448ef6549909fc8f4f37ca3767e": {
     "views": [
      {
       "cell_index": 27
      }
     ]
    },
    "9e89588e16fc49a2968f23ed8bf205ab": {
     "views": []
    },
    "9ea1bdae1fb9428cb4f9deaa0882eaee": {
     "views": []
    },
    "a5a3b255b180444a9b4f0c2012d21525": {
     "views": []
    },
    "a66a51e892254fa58020e334b4a78cc1": {
     "views": []
    },
    "a83d8f75a14a40c68ac584c62329ff82": {
     "views": []
    },
    "aa1d3d31490a4850a903ec7ec7b501ff": {
     "views": []
    },
    "ab2342f479a94c26aa7e5498fbc8241e": {
     "views": []
    },
    "adb559cdf3194978a0c7ca3ccb0d8b89": {
     "views": [
      {
       "cell_index": 27
      }
     ]
    },
    "afb72a31f37540ba9dbdffd4fcccf679": {
     "views": []
    },
    "b079146ebd314fc385a460149067cfd4": {
     "views": []
    },
    "b1164ec220984852bf60f53b643e80f6": {
     "views": []
    },
    "b166a7fd9e5d4aa09fc4ddc9291116df": {
     "views": []
    },
    "b9b84c042466477793376d5399b22da8": {
     "views": []
    },
    "bab49f45c1eb4374aa23dff3392c37fa": {
     "views": [
      {
       "cell_index": 28
      }
     ]
    },
    "bb6b09bc59e040759169aa775e11545d": {
     "views": []
    },
    "bbde2932bf824699be43b13b053feb74": {
     "views": []
    },
    "c437421029d546e6980eebe570147c0c": {
     "views": [
      {
       "cell_index": 28
      }
     ]
    },
    "c4f73d5570704432855934d53f36fb54": {
     "views": [
      {
       "cell_index": 27
      }
     ]
    },
    "c5e36e785fd240afbfd6d8db8cd2f5f9": {
     "views": []
    },
    "c61cdc77fb7743e995987ec675ebaac9": {
     "views": []
    },
    "c6f110672f684c77ad91aaf6c945942c": {
     "views": []
    },
    "ca00015e146f420da4b7e1868ed5415d": {
     "views": []
    },
    "cad2ace040d74c0a82898de366b1c7b9": {
     "views": []
    },
    "cc72316d015b47df87da36d66c69a99c": {
     "views": [
      {
       "cell_index": 28
      }
     ]
    },
    "ccf3fdf1decf44ccb88df9d755d0f603": {
     "views": []
    },
    "cd35b98fb4fc4ffab94b29cb49e0f02b": {
     "views": []
    },
    "cd95de19431a4a44b20749675971977f": {
     "views": []
    },
    "ce80b9b4662d40f59be14add6a2b2548": {
     "views": [
      {
       "cell_index": 28
      }
     ]
    },
    "d03fe0122d764e6f9c454e0bb5b7246e": {
     "views": []
    },
    "d59ac8ae82f842ce8527b83b041bb36d": {
     "views": []
    },
    "d6218721c79e481fb5077b8908822b31": {
     "views": [
      {
       "cell_index": 28
      }
     ]
    },
    "da43993145bb4a949224d8d0daf66d94": {
     "views": []
    },
    "dc78245da1c048fd89c7962b26d69188": {
     "views": []
    },
    "dcd21116ee8a4b0da7dd293175f3e8f2": {
     "views": []
    },
    "df99513094064fe1af68d32236103121": {
     "views": []
    },
    "e0989d08671b4bf4be725a1508ba0dbd": {
     "views": []
    },
    "e11fe951960d4442af827c0fca821d68": {
     "views": [
      {
       "cell_index": 28
      }
     ]
    },
    "e1e4ac78e52847a4b9aa3f359160fe26": {
     "views": []
    },
    "e29ac9dad41c42a1ab13fc18a811de48": {
     "views": []
    },
    "e3ec644a097c4ef9b1aa26768c36b3d8": {
     "views": [
      {
       "cell_index": 28
      }
     ]
    },
    "e40a935a3ac54097a9ed7f610b782cf3": {
     "views": []
    },
    "e6f002e416eb41e991e2e627e63ef114": {
     "views": [
      {
       "cell_index": 27
      }
     ]
    },
    "e93d3bbfe644449fb655087fd63f8831": {
     "views": []
    },
    "eca8a549bbf74468a5bd84dacc82a0a7": {
     "views": []
    },
    "f0291ddeb48b4c959535b89ae26a640f": {
     "views": []
    },
    "f3291a4e633f490f86e128df338a2904": {
     "views": []
    },
    "f6bfec8b44324c1da0f51c62a329db2c": {
     "views": [
      {
       "cell_index": 28
      }
     ]
    },
    "f90530a1c2c34829b1ef0524e573e958": {
     "views": []
    },
    "fb1ac20732f24a26861700ac4ce615b8": {
     "views": [
      {
       "cell_index": 27
      }
     ]
    },
    "fdd89f6de31340b98e89a06ae94ad16d": {
     "views": []
    }
   },
   "version": "1.1.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
